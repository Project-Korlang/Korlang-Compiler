module compiler
// Self-hosted frontend diagnostics


struct Position {
  line: Int;
  column: Int;
  offset: Int;
}

fun Position_new(line: Int, column: Int, offset: Int) -> Position {
  Position { line: line, column: column, offset: offset }
}

struct Span {
  start: Position;
  end: Position;
}

fun Span_new(start: Position, end: Position) -> Span {
  Span { start: start, end: end }
}

struct Diagnostic {
  message: String;
  span: Span;
}

fun Diagnostic_new(message: String, span: Span) -> Diagnostic {
  Diagnostic { message: message, span: span }
}

struct SourceFile {
    path: String;
    content: String;
    line_offsets: Any;
}

struct SourceMap {
    files: Any;
}

fun SourceMap_new() -> SourceMap {
    SourceMap { files: List.new() }
}

fun SourceMap_add_file(self: SourceMap, path: String, content: String) -> SourceFile {
    let offsets = List.new();
    offsets.push(0);
    let i = 0;
    while (i < content.length()) {
        if (content.char_at(i) == '\n') {
            offsets.push(i + 1);
        }
        i = i + 1;
    }
    let file = SourceFile { path: path, content: content, line_offsets: offsets };
    self.files.push(file);
    file
}


struct StringView {
    base: String;
    start: Int;
    length: Int;
}

fun StringView_new(s: String) -> StringView {
    StringView {
        base: s,
        start: 0,
        length: s.length()
    }
}

fun StringView_slice(self: StringView, start: Int, end: Int) -> StringView {
    StringView {
        base: self.base,
        start: self.start + start,
        length: end - start
    }
}

fun StringView_char_at(self: StringView, index: Int) -> Char {
    self.base.char_at(self.start + index)
}

fun StringView_to_string(self: StringView) -> String {
    self.base.substring(self.start, self.start + self.length)
}

fun StringView_equals_str(self: StringView, other: String) -> Bool {
    if (self.length != other.length()) { return false; }
    
    self.to_string() == other
}
// Self-hosted frontend tokens



enum TokenKind {
  Identifier(String);
  IntLiteral(Int);
  FloatLiteral(Float);
  StringLiteral(String);
  CharLiteral(Char);
  BoolLiteral(Bool);
  Keyword(String);

  Plus;
  Minus;
  Star;
  Slash;
  Percent;

  DotPlus;
  DotMinus;
  DotStar;
  DotSlash;
  At;

  Eq;
  PlusEq;
  MinusEq;
  StarEq;
  SlashEq;
  PercentEq;

  EqEq;
  FatArrow;
  NotEq;
  Lt;
  LtEq;
  Gt;
  GtEq;

  AndAnd;
  OrOr;
  Not;

  Arrow;
  Pipe;
  NullCoalesce;
  Question;

  LParen;
  RParen;
  LBrace;
  RBrace;
  LBracket;
  RBracket;

  Comma;
  Semi;
  Colon;
  Dot;

  BitAnd;
  BitOr;
  BitXor;
  ShiftLeft;
  ShiftRight;

  InterpStart;
  InterpEnd;

  Error(String);

  Eof;
}

struct Token {
  kind: TokenKind;
  span: Span;
}

fun Token_new(kind: TokenKind, span: Span) -> Token

fun TokenKind_is_identifier(self: TokenKind) -> Bool
fun TokenKind_ident_value(self: TokenKind) -> String
fun TokenKind_is_string_literal(self: TokenKind) -> Bool
fun TokenKind_string_value(self: TokenKind) -> String
fun TokenKind_is_keyword(self: TokenKind, kw: String) -> Bool

// Task 20.1.33: Optimized token stream serialization
fun Token_serialize(tokens: Any) -> Any {
    let out = List.new();
    let i = 0;
    while (i < tokens.len()) {
        i = i + 1;
    }
    out
}

// --- helpers ---
fun Token_new(kind: TokenKind, span: Span) -> Token {
  Token { kind: kind, span: span }
}

fun TokenKind_is_identifier(self: TokenKind) -> Bool {
  match (self) {
    TokenKind.Identifier(_) => true
    _ => false
  }
}

fun TokenKind_ident_value(self: TokenKind) -> String {
  match (self) {
    TokenKind.Identifier(name) => name
    _ => " "
  }
}

fun TokenKind_is_string_literal(self: TokenKind) -> Bool {
  match (self) {
    TokenKind.StringLiteral(_) => true
    _ => false
  }
}

fun TokenKind_string_value(self: TokenKind) -> String {
  match (self) {
    TokenKind.StringLiteral(s) => s
    _ => " "
  }
}

fun TokenKind_is_keyword(self: TokenKind, kw: String) -> Bool {
  match (self) {
    TokenKind.Keyword(k) => k == kw
    _ => false
  }
}
// Self-hosted frontend AST



struct Program {
  items: Any;
}

enum Visibility {
  Public;
  Internal;
  Private;
}

struct Attribute {
  name: String;
  args: Any;
  span: Span;
}

enum Item {
  Fun(FunDecl, Any, Visibility);
  Struct(StructDecl, Any, Visibility);
  Enum(EnumDecl, Any, Visibility);
  TypeAlias(TypeAliasDecl, Any, Visibility);
  View(ViewDecl, Any, Visibility);
  Resource(ResourceDecl, Any, Visibility);
  Const(VarDecl, Any, Visibility);
  Stmt(Stmt);
}

struct FunDecl {
  name: String;
  generics: Any;
  params: Any;
  ret: TypeRef?;
  body: Block;
  nogc: Bool;
  span: Span;
}

struct Param {
  name: String;
  ty: TypeRef;
  span: Span;
}

struct StructDecl {
  name: String;
  generics: Any;
  fields: Any;
  span: Span;
}

struct FieldDecl {
  name: String;
  ty: TypeRef;
  span: Span;
}

struct EnumDecl {
  name: String;
  variants: Any;
  span: Span;
}

struct VariantDecl {
  name: String;
  payload: Any;
  span: Span;
}

struct TypeAliasDecl {
  name: String;
  target: TypeRef;
  span: Span;
}

struct ViewDecl {
  name: String;
  params: Any;
  body: Any;
  span: Span;
}

struct ViewNode {
  name: String;
  args: Any;
  children: Any;
  span: Span;
}

struct ViewArg {
  name: String?;
  value: Expr;
  span: Span;
}

struct ResourceDecl {
  name: String;
  resource_type: String;
  entries: Any;
  span: Span;
}

struct ResourceEntry {
  key: String;
  value: Expr;
  span: Span;
}

struct VarDecl {
  mutable: Bool;
  name: String;
  ty: TypeRef?;
  value: Expr;
  span: Span;
}

enum Stmt {
  Var(VarDecl);
  Expr(Expr, Span);
  Return(Expr?, Span);
  Break(Span);
  Continue(Span);
  If(Expr, Block, Stmt?, Span);
  While(Expr, Block, Span);
  For(String, Expr, Block, Span);
  Match(Expr, Any, Span);
  Block(Block);
}

struct Block {
  stmts: Any;
  tail: Expr?;
  span: Span;
}

struct MatchArm {
  pat: Pattern;
  body: Expr;
  span: Span;
}

enum Expr {
  Literal(Literal, Span);
  Ident(String, Span);
  Unary(UnaryOp, Expr, Span);
  Binary(Expr, BinaryOp, Expr, Span);
  Assign(Expr, AssignOp, Expr, Span);
  Call(Expr, Any, Span);
  Member(Expr, String, Span);
  Index(Expr, Expr, Span);
  If(Expr, Block, Block, Span);
  Match(Expr, Any, Span);
  Block(Block);
  Array(Any, Span);
  Tensor(Any>, Span);
  Interpolated(Any, Span);
}

enum Literal {
  Int(Int);
  Float(Float);
  String(String);
  Char(Char);
  Bool(Bool);
}

enum UnaryOp {
  Not;
  Neg;
  Pos;
  BitNot;
}

enum BinaryOp {
  Add;
  Sub;
  Mul;
  Div;
  Mod;
  DotAdd;
  DotSub;
  DotMul;
  DotDiv;
  MatMul;
  Eq;
  NotEq;
  Lt;
  LtEq;
  Gt;
  GtEq;
  And;
  Or;
  NullCoalesce;
  Pipe;
  Arrow;
}

enum AssignOp {
  Assign;
  AddAssign;
  SubAssign;
  MulAssign;
  DivAssign;
  ModAssign;
}

struct FieldPattern {
  name: String;
  pat: Pattern;
}

enum Pattern {
  Ident(String, Span);
  Wildcard(Span);
  Literal(Literal, Span);
  Tuple(Any, Span);
  Variant(String, Any, Span);
  Struct(String, Any, Span);
}

enum TypeRef {
  Named(String, Any, Span);
  Tuple(Any, Span);
  Array(TypeRef, Span);
  Tensor(TypeRef, Any, Span);
  Optional(TypeRef, Span);
  NonNull(TypeRef, Span);
}

enum ShapeDim {
  Int(Int);
  Ident(String);
  Unknown;
}
// Shared type system for self-hosted sema



enum Type {
  Int;
  UInt;
  Float;
  Bool;
  Char;
  String;
  Unit;
  Any;
  Nothing;
  Number;
  Tuple(Any);
  Array(Type);
  Tensor(Type);
  Named(String);
  Func(Any, Type);
  Var(Int);
  Unknown;
}

fun type_from_ref(tr: TypeRef) -> Type

fun type_from_ref(tr: TypeRef) -> Type {
  match (tr) {
    TypeRef.Named(name, _) => {
      if (name == "Int") { Type.Int }
      else if (name == "UInt") { Type.UInt }
      else if (name == "Float") { Type.Float }
      else if (name == "Bool") { Type.Bool }
      else if (name == "Char") { Type.Char }
      else if (name == "String") { Type.String }
      else if (name == "Any") { Type.Any }
      else if (name == "Nothing") { Type.Nothing }
      else { Type.Named(name) }
    }
    TypeRef.Tuple(elems, _) => {
      let out = List.new();
      let i = 0;
      while (i < elems.len()) {
        out.push(type_from_ref(elems[i]));
        i = i + 1;
      }
      Type.Tuple(out)
    }
    TypeRef.Array(inner, _) => Type.Array(type_from_ref(inner))
    TypeRef.Tensor(elem, _, _) => Type.Tensor(type_from_ref(elem))
    TypeRef.Optional(inner, _) => type_from_ref(inner)
    TypeRef.NonNull(inner, _) => type_from_ref(inner)
  }
}
// Self-hosted semantic analysis: symbol table with scope tree



enum SymbolKind {
  Var;
  Func;
  Struct;
  Enum;
  TypeAlias;
}

struct Symbol {
  name: String;
  ty: Type;
  mutable: Bool;
  kind: SymbolKind;
  visibility: Visibility;
}

struct Scope {
  symbols: Any;
  parent: Int;
}

struct SymbolTable {
  scopes: Any;
  current: Int;
}

fun SymbolTable_new() -> SymbolTable
fun SymbolTable_enter(self: SymbolTable) -> Int
fun SymbolTable_exit(self: SymbolTable)
fun SymbolTable_define(self: SymbolTable, name: String, ty: Type, mutable: Bool, kind: SymbolKind, visibility: Visibility) -> Bool
fun SymbolTable_lookup(self: SymbolTable, name: String) -> Symbol?

fun SymbolTable_new() -> SymbolTable {
  let scopes = List.new();
  scopes.push(Scope { symbols: List.new(), parent: -1 });
  SymbolTable { scopes: scopes, current: 0 }
}

fun SymbolTable_enter(self: SymbolTable) -> Int {
  let parent = self.current;
  self.scopes.push(Scope { symbols: List.new(), parent: parent });
  self.current = self.scopes.len() - 1;
  self.current
}

fun SymbolTable_exit(self: SymbolTable) {
  if (self.current != 0) {
    self.current = self.scopes[self.current].parent;
  }
}

fun SymbolTable_define(self: SymbolTable, name: String, ty: Type, mutable: Bool, kind: SymbolKind, visibility: Visibility) -> Bool {
  let scope = self.scopes[self.current];
  let i = 0;
  while (i < scope.symbols.len()) {
    if (scope.symbols[i].name == name) { return false; }
    i = i + 1;
  }
  scope.symbols.push(Symbol { name: name, ty: ty, mutable: mutable, kind: kind, visibility: visibility });
  true
}

fun SymbolTable_lookup(self: SymbolTable, name: String) -> Symbol? {
  let idx = self.current;
  let cur = idx;
  while (cur >= 0) {
    let scope = self.scopes[cur];
    let j = 0;
    while (j < scope.symbols.len()) {
      if (scope.symbols[j].name == name) { return scope.symbols[j]; }
      j = j + 1;
    }
    if (scope.parent < 0) { break; }
    cur = scope.parent;
  }
  null
}
// Self-hosted frontend lexer (Korlang-in-Korlang)



struct InterpContext {
  resume_string: Bool;
  depth: Int;
}

struct Lexer {
  src: String;
  chars: Any;
  pos: Int;
  line: Int;
  col: Int;
  pending: Any;
  pending_pos: Int;
  in_string: Bool;
  interp_stack: Any;
}

fun Lexer_new(src: String) -> Lexer;

fun Lexer_tokenize(self) -> Any;

fun Lexer_lex_ident_or_keyword(self) -> Any;
fun Lexer_lex_number(self) -> Any;
fun Lexer_lex_string_segment(self) -> Any;
fun Lexer_lex_char(self) -> Any;
fun Lexer_lex_symbol(self) -> Any;

fun Lexer_skip_whitespace_and_comments(self);

fun Lexer_is_eof(self) -> Bool;
fun Lexer_peek(self) -> Char;
fun Lexer_peek_next(self) -> Char;
fun Lexer_advance(self);
fun Lexer_position(self) -> Any;

fun Lexer_in_interpolation(self) -> Bool;
fun Lexer_push_interpolation(self: Lexer, resume_string: Bool);

fun Lexer_pending_take(self) -> Any;

fun is_alpha(c: Char) -> Bool;
fun is_digit(c: Char) -> Bool;
fun is_hex(c: Char) -> Bool;
fun is_whitespace(c: Char) -> Bool;

// --- Implementation ---

fun Lexer_new(src: String) -> Lexer {
  let chars = src.chars();
  Lexer {
    src: src,
    chars: chars,
    pos: 0,
    line: 1,
    col: 1,
    pending: List.new(),
    pending_pos: 0,
    in_string: false,
    interp_stack: List.new(),
  }
}

fun Lexer_tokenize(self) -> Any {
  let tokens = List.new();
  let diags = List.new();

  while (!self.is_eof() || self.in_string || self.pending_pos < self.pending.len() || self.in_interpolation()) {
    let pending = self.pending_take();
    if (pending != null) {
      tokens.push(pending);
      continue;
    }

    if (self.in_string && !self.in_interpolation()) {
      let seg = self.lex_string_segment();
      if (seg.is_ok()) {
        let tok = seg.ok();
        if (tok != null) { tokens.push(tok); }
      } else {
        diags.push(seg.err());
      }
      continue;
    }

    self.skip_whitespace_and_comments();
    if (self.is_eof()) { break; }

    let c = self.peek();
    let tok = if (is_alpha(c) || c == '_') {
      self.lex_ident_or_keyword()
    } else if (is_digit(c)) {
      self.lex_number()
    } else if (c == '"') {
      self.advance();
      self.in_string = true;
      self.lex_string_segment()
    } else if (c == '\'') {
      self.lex_char()
    } else {
      self.lex_symbol()
    };

    if (tok.is_ok()) {
      let t = tok.ok();
      if (t != null) { tokens.push(t); }
    } else {
      diags.push(tok.err());
    }
  }

  if (self.in_interpolation()) {
    diags.push(Diagnostic_new("unterminated interpolation", Span_new(self.position(), self.position())));
  }

  tokens.push(Token_new(TokenKind.Eof, Span_new(self.position(), self.position())));

  if (diags.len() == 0) {
    return Result.ok(tokens);
  }
  Result.err(diags)
}

fun Lexer_lex_ident_or_keyword(self) -> Any {
  let start_pos = self.position();
  let start_idx = self.pos;
  self.advance();
  while (!self.is_eof()) {
    let c = self.peek();
    if (is_alpha(c) || is_digit(c) || c == '_') {
      self.advance();
    } else {
      break;
    }
  }
  let s = self.src.slice(start_idx, self.pos);
  let keywords = ["fun", "gpu", "let", "var", "if", "else", "match", "for", "while",
    "break", "continue", "return", "view", "resource", "state", "spawn", "@nogc",
    "import", "as", "struct", "enum", "type", "in", "interface", "module", "class"];
  let kind = if keywords.contains(s) {
    TokenKind.Keyword(s)
  } else if (s == "true") {
    TokenKind.BoolLiteral(true)
  } else if (s == "false") {
    TokenKind.BoolLiteral(false)
  } else {
      TokenKind.Identifier(s)
    };

  Result.ok(Token_new(kind, Span_new(start_pos, self.position())))
}

fun Lexer_lex_number(self) -> Any {
  let start_pos = self.position();
  let start = self.pos;
  if (self.peek() == '0' && (self.peek_next() == 'x' || self.peek_next() == 'X')) {
    self.advance();
    self.advance();
    let hex_start = self.pos;
    while (!self.is_eof() && is_hex(self.peek())) {
      self.advance();
    }
    if (hex_start == self.pos) {
      return Result.err(Diagnostic_new("invalid hex literal", Span_new(start_pos, self.position())));
    }
    let s = self.src.slice(hex_start, self.pos);
    let v = Int.parse_radix(s, 16);
    return Result.ok(Token_new(TokenKind.IntLiteral(v), Span_new(start_pos, self.position())));
  }

  while (!self.is_eof() && is_digit(self.peek())) {
    self.advance();
  }

  let is_float = false;
  if (!self.is_eof() && self.peek() == '.' && is_digit(self.peek_next())) {
    is_float = true;
    self.advance();
    while (!self.is_eof() && is_digit(self.peek())) {
      self.advance();
    }
  }
  if (!self.is_eof() && (self.peek() == 'e' || self.peek() == 'E')) {
    is_float = true;
    self.advance();
    if (self.peek() == '+' || self.peek() == '-') {
      self.advance();
    }
    while (!self.is_eof() && is_digit(self.peek())) {
      self.advance();
    }
  }

  let s = self.src.slice(start, self.pos);
  if (is_float) {
    let v = Float.parse(s);
    Result.ok(Token_new(TokenKind.FloatLiteral(v), Span_new(start_pos, self.position())))
  } else {
    let v = Int.parse(s);
    Result.ok(Token_new(TokenKind.IntLiteral(v), Span_new(start_pos, self.position())))
  }
}

fun Lexer_lex_string_segment(self) -> Any {
  let start = self.position();
  let out = " ";
  while (!self.is_eof()) {
    let c = self.peek();
    if (c == '"') {
      let end_pos = self.position();
      self.advance();
      self.in_string = false;
      if (out.len() == 0) { return Result.ok(null); }
      return Result.ok(Token_new(TokenKind.StringLiteral(out), Span_new(start, end_pos)));
    }
    if (c == '\\') {
      self.advance();
      if (self.is_eof()) {
        return Result.err(Diagnostic_new("unterminated escape", Span_new(start, self.position())));
      }
      let esc = self.peek();
      let real = if (esc == 'n') { '\n' }
        else if (esc == 'r') { '\r' }
        else if (esc == 't') { '\t' }
        else if (esc == '0') { '\0' }
        else if (esc == '\\') { '\\' }
        else if (esc == '"') { '"' }
        else if (esc == '{') { '{' }
        else if (esc == '}') { '}' }
        else { return Result.err(Diagnostic_new("invalid escape", Span_new(start, self.position()))); };
      out = out + real.to_string();
      self.advance();
      continue;
    }
    if (c == '{') {
      let interp_start = self.position();
      if (out.len() > 0) {
        let span = Span_new(start, interp_start);
        self.advance();
        self.push_interpolation(true);
        let interp_span = Span_new(interp_start, self.position());
        self.pending.push(Token_new(TokenKind.InterpStart, interp_span));
        return Result.ok(Token_new(TokenKind.StringLiteral(out), span));
      }
      self.advance();
      self.push_interpolation(true);
      let interp_span = Span_new(interp_start, self.position());
      return Result.ok(Token_new(TokenKind.InterpStart, interp_span));
    }
    out = out + c.to_string();
    self.advance();
  }
  Result.err(Diagnostic_new("unterminated string", Span_new(start, self.position())))
}

fun Lexer_lex_char(self) -> Any {
  let start = self.position();
  self.advance();
  if (self.is_eof()) {
    return Result.err(Diagnostic_new("unterminated char", Span_new(start, self.position())));
  }
  let c = self.peek();
  let ch = if (c == '\\') {
    self.advance();
    let esc = self.peek();
    let real = if (esc == 'n') { '\n' }
      else if (esc == 'r') { '\r' }
      else if (esc == 't') { '\t' }
      else if (esc == '0') { '\0' }
      else if (esc == '\\') { '\\' }
      else if (esc == '\'') { '\'' }
      else { return Result.err(Diagnostic_new("invalid escape", Span_new(start, self.position()))); };
    self.advance();
    real
  } else {
    self.advance();
    c
  };
  if (self.is_eof() || self.peek() != '\'') {
    return Result.err(Diagnostic_new("unterminated char", Span_new(start, self.position())));
  }
  self.advance();
  Result.ok(Token_new(TokenKind.CharLiteral(ch), Span_new(start, self.position())))
}

fun Lexer_lex_symbol(self) -> Any {
  let start = self.position();
  let c = self.peek();
  let next = self.peek_next();

  if (c == '}' && self.in_interpolation()) {
    self.advance();
    let top = self.interp_stack.last();
    if (top != null) {
      if (top.depth == 0) {
        self.interp_stack.pop();
        if (top.resume_string) { self.in_string = true; }
        return Result.ok(Token_new(TokenKind.InterpEnd, Span_new(start, self.position())));
      }
      top.depth = top.depth - 1;
      return Result.ok(Token_new(TokenKind.RBrace, Span_new(start, self.position())));
    }
  }

  if (c == '{' && self.in_interpolation()) {
    self.advance();
    let top = self.interp_stack.last();
    if (top != null) { top.depth = top.depth + 1; }
    return Result.ok(Token_new(TokenKind.LBrace, Span_new(start, self.position())));
  }

  if (c == '@' && (is_alpha(next) || next == '_')) {
    self.advance();
    let ident_start = self.pos;
    while (!self.is_eof()) {
      let ch = self.peek();
      if (is_alpha(ch) || is_digit(ch) || ch == '_') {
        self.advance();
      } else { break; }
    }
    let name = self.src.slice(ident_start, self.pos);
    let full = "@" + name;
    let kind = if (name == "nogc" || name == "import" || name == "bridge") {
      TokenKind.Keyword(full)
    } else {
      TokenKind.Identifier(full)
    };
    return Result.ok(Token_new(kind, Span_new(start, self.position())));
  }

  let tok = if (c == '-' && next == '>') { self.advance(); self.advance(); TokenKind.Arrow }
    else if (c == '|' && next == '>') { self.advance(); self.advance(); TokenKind.Pipe }
    else if (c == '?' && next == ':') { self.advance(); self.advance(); TokenKind.NullCoalesce }
    else if (c == '=' && next == '=') { self.advance(); self.advance(); TokenKind.EqEq }
    else if (c == '=' && next == '>') { self.advance(); self.advance(); TokenKind.FatArrow }
    else if (c == '!' && next == '=') { self.advance(); self.advance(); TokenKind.NotEq }
    else if (c == '<' && next == '=') { self.advance(); self.advance(); TokenKind.LtEq }
    else if (c == '>' && next == '=') { self.advance(); self.advance(); TokenKind.GtEq }
    else if (c == '&' && next == '&') { self.advance(); self.advance(); TokenKind.AndAnd }
    else if (c == '|' && next == '|') { self.advance(); self.advance(); TokenKind.OrOr }
    else if (c == '.' && next == '+') { self.advance(); self.advance(); TokenKind.DotPlus }
    else if (c == '.' && next == '-') { self.advance(); self.advance(); TokenKind.DotMinus }
    else if (c == '.' && next == '*') { self.advance(); self.advance(); TokenKind.DotStar }
    else if (c == '.' && next == '/') { self.advance(); self.advance(); TokenKind.DotSlash }
    else if (c == '+' && next == '=') { self.advance(); self.advance(); TokenKind.PlusEq }
    else if (c == '-' && next == '=') { self.advance(); self.advance(); TokenKind.MinusEq }
    else if (c == '*' && next == '=') { self.advance(); self.advance(); TokenKind.StarEq }
    else if (c == '/' && next == '=') { self.advance(); self.advance(); TokenKind.SlashEq }
    else if (c == '%' && next == '=') { self.advance(); self.advance(); TokenKind.PercentEq }
    else if (c == '@' && next == '{') { self.advance(); self.advance(); self.push_interpolation(false); TokenKind.InterpStart }
    else {
      self.advance();
      if (c == '+') { TokenKind.Plus }
      else if (c == '-') { TokenKind.Minus }
      else if (c == '*') { TokenKind.Star }
      else if (c == '/') { TokenKind.Slash }
      else if (c == '%') { TokenKind.Percent }
      else if (c == '@') { TokenKind.At }
      else if (c == '=') { TokenKind.Eq }
      else if (c == '<') { TokenKind.Lt }
      else if (c == '>') { TokenKind.Gt }
      else if (c == '!') { TokenKind.Not }
      else if (c == '?') { TokenKind.Question }
      else if (c == '(') { TokenKind.LParen }
      else if (c == ')') { TokenKind.RParen }
      else if (c == '{') { TokenKind.LBrace }
      else if (c == '}') { TokenKind.RBrace }
      else if (c == '[') { TokenKind.LBracket }
      else if (c == ']') { TokenKind.RBracket }
      else if (c == ',') { TokenKind.Comma }
      else if (c == ';') { TokenKind.Semi }
      else if (c == ':') { TokenKind.Colon }
      else if (c == '.') { TokenKind.Dot }
      else { return Result.err(Diagnostic_new("unexpected character", Span_new(start, self.position()))); }
    };

  Result.ok(Token_new(tok, Span_new(start, self.position())))
}

fun Lexer_skip_whitespace_and_comments(self) {
  while (true) {
    while (!self.is_eof() && is_whitespace(self.peek())) { self.advance(); }
    if (self.is_eof()) { return; }
    if (self.peek() == '/' && self.peek_next() == '/') {
      self.advance(); self.advance();
      while (!self.is_eof() && self.peek() != '\n') { self.advance(); }
      continue;
    }
    if (self.peek() == '/' && self.peek_next() == '*') {
      self.advance(); self.advance();
      while (!self.is_eof()) {
        if (self.peek() == '*' && self.peek_next() == '/') { self.advance(); self.advance(); break; }
        self.advance();
      }
      continue;
    }
    break;
  }
}

fun Lexer_is_eof(self) -> Bool { self.pos >= self.chars.len() }

fun Lexer_peek(self) -> Char { self.chars[self.pos] }

fun Lexer_peek_next(self) -> Char {
  if (self.pos + 1 >= self.chars.len()) { '\0' } else { self.chars[self.pos + 1] }
}

fun Lexer_advance(self) {
  if (self.is_eof()) { return; }
  if (self.peek() == '\n') {
    self.line = self.line + 1;
    self.col = 1;
  } else {
    self.col = self.col + 1;
  }
  self.pos = self.pos + 1;
}

fun Lexer_position(self) -> Any { Position_new(self.line, self.col, self.pos) }

fun Lexer_in_interpolation(self) -> Bool { self.interp_stack.len() > 0 }

fun Lexer_push_interpolation(self: Lexer, resume_string: Bool) {
  self.interp_stack.push(InterpContext { resume_string: resume_string, depth: 0 });
}

fun Lexer_pending_take(self) -> Any {
  if (self.pending_pos >= self.pending.len()) { return null; }
  let tok = self.pending[self.pending_pos];
  self.pending_pos = self.pending_pos + 1;
  tok
}

fun is_alpha(c: Char) -> Bool {
  (c >= 'a' && c = 'A' && c <= 'Z')
}

fun is_digit(c: Char) -> Bool { c >= '0' && c <= '9' }

fun is_hex(c: Char) -> Bool {
  is_digit(c) || (c >= 'a' && c = 'A' && c <= 'F')
}

fun is_whitespace(c: Char) -> Bool {
  c == ' ' || c == '\t' || c == '\n' || c == '\r'
}
// Self-hosted frontend parser (Korlang-in-Korlang)



struct Parser {
  tokens: Any;
  pos: Int;
  diags: Any;
}

enum InfixOp {
  Binary(BinaryOp);
  Assign(AssignOp);
}
struct InfixPower {
  l_bp: Int;
  r_bp: Int;
  op: InfixOp;
}

fun Parser_new(tokens: Any) -> Parser
fun Parser_parse_program(self: Parser) -> Any

// Item parsing
fun Parser_parse_item(self: Parser) -> Any
fun Parser_parse_fun(self: Parser, nogc: Bool) -> Any
fun Parser_parse_struct(self: Parser) -> Any
fun Parser_parse_enum(self: Parser) -> Any
fun Parser_parse_type_alias(self: Parser) -> Any
fun Parser_parse_view(self: Parser) -> Any
fun Parser_parse_view_block(self: Parser) -> Any
fun Parser_parse_view_args(self: Parser) -> Any
fun Parser_parse_view_arg(self: Parser) -> Any
fun Parser_parse_resource(self: Parser) -> Any

// Statements
fun Parser_parse_stmt(self: Parser) -> Any
fun Parser_parse_var_decl(self: Parser) -> Any
fun Parser_parse_var_decl_with(self: Parser, immutable: Bool) -> Any
fun Parser_parse_block(self: Parser) -> Any

// Expressions
fun Parser_parse_expr(self: Parser) -> Any
fun Parser_parse_expr_bp(self: Parser, min_bp: Int) -> Any
fun Parser_parse_prefix(self: Parser) -> Any
fun Parser_parse_if_expr(self: Parser) -> Any
fun Parser_parse_match_expr(self: Parser) -> Any
fun Parser_parse_match_arms(self: Parser) -> Any
fun Parser_parse_pattern(self: Parser) -> Any
fun Parser_parse_array_literal(self: Parser) -> Any
fun Parser_parse_tensor_literal(self: Parser, start: Span) -> Any
fun Parser_parse_tensor_row(self: Parser) -> Any
fun Parser_parse_interpolated_string(self: Parser, first: Expr) -> Any

// Types
fun Parser_parse_type_ref(self: Parser) -> Any
fun Parser_parse_shape_ref(self: Parser) -> Any
fun Parser_parse_shape_dim(self: Parser) -> Any

// Params/idents
fun Parser_parse_param_list(self: Parser) -> Any
fun Parser_parse_param(self: Parser) -> Any
fun Parser_parse_qualified_ident(self: Parser) -> Any

// Helpers
fun Parser_infix_binding_power(self: Parser) -> InfixPower?
fun Parser_current(self: Parser) -> Token
fun Parser_current_span(self: Parser) -> Span
fun Parser_prev_span(self: Parser) -> Span
fun Parser_span_of(self: Parser, expr: Expr) -> Span
fun Parser_advance(self: Parser) -> Token
fun Parser_at_eof(self: Parser) -> Bool
fun Parser_check_kind(self: Parser, kind: TokenKind) -> Bool
fun Parser_peek_kind(self: Parser, kind: TokenKind) -> Bool
fun Parser_match_kind(self: Parser, kind: TokenKind) -> Bool
fun Parser_match_keyword(self: Parser, kw: String) -> Bool
fun Parser_check_keyword(self: Parser, kw: String) -> Bool
fun Parser_expect_keyword(self: Parser, kw: String) -> Any
fun Parser_expect_kind(self: Parser, kind: TokenKind) -> Any
fun Parser_expect_ident(self: Parser) -> Any
fun Parser_error(self: Parser, msg: String)
fun Parser_error_at(self: Parser, span: Span, msg: String)
fun Parser_synchronize(self: Parser)

// --- Implementation ---

fun Parser_new(tokens: Any) -> Parser {
  Parser { tokens: tokens, pos: 0, diags: List.new() }
}

fun Parser_parse_program(self: Parser) -> Any {
  let items = List.new();
  while (!self.at_eof()) {
    let item = self.parse_item();
    if (item.is_ok()) {
      items.push(item.ok());
    } else {
      self.synchronize();
    }
  }

  if (self.diags.len() == 0) {
    Result.ok(Program { items: items })
  } else {
    Result.err(self.diags)
  }
}

fun Parser_parse_item(self: Parser) -> Any {
  let attrs = self.parse_attributes()?;
  if (self.match_keyword("@nogc")) {
    self.expect_keyword("fun")?;
    return Result.ok(Item.Fun(self.parse_fun(true)?, attrs, Visibility.Public));
  }
  if (self.match_keyword("gpu")) {
    self.expect_keyword("fun")?;
    return Result.ok(Item.Fun(self.parse_fun(false)?));
  }
  if (self.match_keyword("fun")) { return Result.ok(Item.Fun(self.parse_fun(false)?, attrs, Visibility.Public)); }
  if (self.match_keyword("struct")) { return Result.ok(Item.Struct(self.parse_struct()?, attrs, Visibility.Public)); }
  if (self.match_keyword("enum")) { return Result.ok(Item.Enum(self.parse_enum()?, attrs, Visibility.Public)); }
  if (self.match_keyword("type")) { return Result.ok(Item.TypeAlias(self.parse_type_alias()?, attrs, Visibility.Public)); }
  if (self.match_keyword("view")) { return Result.ok(Item.View(self.parse_view()?, attrs, Visibility.Public)); }
  if (self.match_keyword("resource")) { return Result.ok(Item.Resource(self.parse_resource()?, attrs, Visibility.Public)); }
  if (self.check_keyword("let") || self.check_keyword("var")) {
    return Result.ok(Item.Const(self.parse_var_decl()?, attrs, Visibility.Public));
  }
  Result.ok(Item.Stmt(self.parse_stmt()?))
}

fun Parser_parse_fun(self: Parser, nogc: Bool) -> Any {
  let start = self.prev_span();
  let name = self.expect_ident()?;
  let generics = List.new(); // Simplified placeholder
  let params = self.parse_param_list()?;
  let ret = if (self.match_kind(TokenKind.Arrow)) { self.parse_type_ref()? } else { null };
  let body = self.parse_block()?;
  let end = body.span.end;
  Result.ok(FunDecl { name: name, generics: generics, params: params, ret: ret, body: body, nogc: nogc, span: Span_new(start.start, end) })
}

fun Parser_parse_struct(self: Parser) -> Any {
  let start = self.prev_span();
  let name = self.expect_ident()?;
  let generics = List.new(); // Simplified placeholder
  self.expect_kind(TokenKind.LBrace)?;
  let fields = List.new();
  while (!self.check_kind(TokenKind.RBrace) && !self.at_eof()) {
    let field_name = self.expect_ident()?;
    self.expect_kind(TokenKind.Colon)?;
    let ty = self.parse_type_ref()?;
    let semi = self.expect_kind(TokenKind.Semi)?;
    fields.push(FieldDecl { name: field_name, ty: ty, span: semi.span });
  }
  let end = self.expect_kind(TokenKind.RBrace)?;
  Result.ok(StructDecl { name: name, generics: generics, fields: fields, span: Span_new(start.start, end.span.end) })
}

fun Parser_parse_enum(self: Parser) -> Any {
  let start = self.prev_span();
  let name = self.expect_ident()?;
  self.expect_kind(TokenKind.LBrace)?;
  let variants = List.new();
  while (!self.check_kind(TokenKind.RBrace) && !self.at_eof()) {
    let vname = self.expect_ident()?;
    let payload = List.new();
    if (self.match_kind(TokenKind.LParen)) {
      if (!self.check_kind(TokenKind.RParen)) {
        payload.push(self.parse_type_ref()?);
        while (self.match_kind(TokenKind.Comma)) { payload.push(self.parse_type_ref()?); }
      }
      self.expect_kind(TokenKind.RParen)?;
    }
    let semi = self.expect_kind(TokenKind.Semi)?;
    variants.push(VariantDecl { name: vname, payload: payload, span: semi.span });
  }
  let end = self.expect_kind(TokenKind.RBrace)?;
  Result.ok(EnumDecl { name: name, variants: variants, span: Span_new(start.start, end.span.end) })
}

fun Parser_parse_type_alias(self: Parser) -> Any {
  let start = self.prev_span();
  let name = self.expect_ident()?;
  self.expect_kind(TokenKind.Eq)?;
  let target = self.parse_type_ref()?;
  let end = self.expect_kind(TokenKind.Semi)?;
  Result.ok(TypeAliasDecl { name: name, target: target, span: Span_new(start.start, end.span.end) })
}

fun Parser_parse_view(self: Parser) -> Any {
  let start = self.prev_span();
  let name = self.expect_ident()?;
  let params = self.parse_param_list()?;
  let body = self.parse_view_block()?;
  let end = if (body.len() > 0) { body[body.len() - 1].span } else { start };
  Result.ok(ViewDecl { name: name, params: params, body: body, span: Span_new(start.start, end.end) })
}

fun Parser_parse_view_block(self: Parser) -> Any {
  self.expect_kind(TokenKind.LBrace)?;
  let nodes = List.new();
  while (!self.check_kind(TokenKind.RBrace) && !self.at_eof()) {
    let name = self.expect_ident()?;
    let args = self.parse_view_args()?;
    let children = if (self.check_kind(TokenKind.LBrace)) { self.parse_view_block()? } else { List.new() };
    let semi = self.expect_kind(TokenKind.Semi)?;
    nodes.push(ViewNode { name: name, args: args, children: children, span: semi.span });
  }
  self.expect_kind(TokenKind.RBrace)?;
  Result.ok(nodes)
}

fun Parser_parse_view_args(self: Parser) -> Any {
  self.expect_kind(TokenKind.LParen)?;
  let args = List.new();
  if (!self.check_kind(TokenKind.RParen)) {
    args.push(self.parse_view_arg()?);
    while (self.match_kind(TokenKind.Comma)) { args.push(self.parse_view_arg()?); }
  }
  self.expect_kind(TokenKind.RParen)?;
  Result.ok(args)
}

fun Parser_parse_view_arg(self: Parser) -> Any {
  let start = self.current_span();
  let name = null;
  if (self.current().kind.is_identifier() && self.peek_kind(TokenKind.Colon)) {
    name = self.expect_ident()?;
    self.expect_kind(TokenKind.Colon)?;
  }
  let value = self.parse_expr()?;
  Result.ok(ViewArg { name: name, value: value, span: Span_new(start.start, self.prev_span().end) })
}

fun Parser_parse_resource(self: Parser) -> Any {
  let start = self.prev_span();
  let name = self.expect_ident()?;
  self.expect_kind(TokenKind.LParen)?;
  let resource_type = self.parse_qualified_ident()?;
  self.expect_kind(TokenKind.RParen)?;
  self.expect_kind(TokenKind.LBrace)?;
  let entries = List.new();
  while (!self.check_kind(TokenKind.RBrace) && !self.at_eof()) {
    let key = self.expect_ident()?;
    self.expect_kind(TokenKind.Colon)?;
    let value = self.parse_expr()?;
    let semi = self.expect_kind(TokenKind.Semi)?;
    entries.push(ResourceEntry { key: key, value: value, span: semi.span });
  }
  let end = self.expect_kind(TokenKind.RBrace)?;
  Result.ok(ResourceDecl { name: name, resource_type: resource_type, entries: entries, span: Span_new(start.start, end.span.end) })
}

fun Parser_parse_stmt(self: Parser) -> Any {
  if (self.match_keyword("let")) { return Result.ok(Stmt.Var(self.parse_var_decl_with(true)?)); }
  if (self.match_keyword("var")) { return Result.ok(Stmt.Var(self.parse_var_decl_with(false)?)); }
  if (self.match_keyword("return")) {
    let start = self.prev_span();
    let expr = if (self.check_kind(TokenKind.Semi)) { null } else { self.parse_expr()? };
    let end = self.expect_kind(TokenKind.Semi)?;
    return Result.ok(Stmt.Return(expr, Span_new(start.start, end.span.end)));
  }
  if (self.match_keyword("break")) {
    let start = self.prev_span();
    let end = self.expect_kind(TokenKind.Semi)?;
    return Result.ok(Stmt.Break(Span_new(start.start, end.span.end)));
  }
  if (self.match_keyword("continue")) {
    let start = self.prev_span();
    let end = self.expect_kind(TokenKind.Semi)?;
    return Result.ok(Stmt.Continue(Span_new(start.start, end.span.end)));
  }
  if (self.match_keyword("if")) {
    let start = self.prev_span();
    let cond = self.parse_expr()?;
    let then_block = self.parse_block()?;
    let else_stmt = null;
    if (self.match_keyword("else")) {
      if (self.check_keyword("if")) {
        else_stmt = self.parse_stmt()?;
      } else {
        else_stmt = Stmt.Block(self.parse_block()?);
      }
    }
    let end = if (else_stmt != null) {
      match (else_stmt) {
        Stmt.Block(b) => b.span.end
        Stmt.If(_, _, _, s) => s.end
        _ => then_block.span.end
      }
    } else { then_block.span.end };
    return Result.ok(Stmt.If(cond, then_block, else_stmt, Span_new(start.start, end)));
  }
  if (self.match_keyword("while")) {
    let start = self.prev_span();
    let cond = self.parse_expr()?;
    let body = self.parse_block()?;
    return Result.ok(Stmt.While(cond, body, Span_new(start.start, body.span.end)));
  }
  if (self.match_keyword("for")) {
    let start = self.prev_span();
    let name = self.expect_ident()?;
    self.expect_keyword("in")?;
    let iter = self.parse_expr()?;
    let body = self.parse_block()?;
    return Result.ok(Stmt.For(name, iter, body, Span_new(start.start, body.span.end)));
  }
  if (self.match_keyword("match")) {
    let start = self.prev_span();
    let expr = self.parse_expr()?;
    let arms = self.parse_match_arms()?;
    let end = if (arms.len() > 0) { arms[arms.len() - 1].span.end } else { start.end };
    return Result.ok(Stmt.Match(expr, arms, Span_new(start.start, end)));
  }
  if (self.check_kind(TokenKind.LBrace)) {
    return Result.ok(Stmt.Block(self.parse_block()?));
  }

  let expr = self.parse_expr()?;
  let end = self.expect_kind(TokenKind.Semi)?;
  Result.ok(Stmt.Expr(expr, Span_new(end.span.start, end.span.end)))
}

fun Parser_parse_var_decl(self: Parser) -> Any {
  if (self.match_keyword("let")) { self.parse_var_decl_with(true) }
  else if (self.match_keyword("var")) { self.parse_var_decl_with(false) }
  else { self.error("expected 'let' or 'var'"); Result.err(false) }
}

fun Parser_parse_var_decl_with(self: Parser, immutable: Bool) -> Any {
  let start = self.prev_span();
  let name = self.expect_ident()?;
  let ty = if (self.match_kind(TokenKind.Colon)) { self.parse_type_ref()? } else { null };
  self.expect_kind(TokenKind.Eq)?;
  let value = self.parse_expr()?;
  let end = if (self.match_kind(TokenKind.Semi)) { self.prev_span() } else { self.prev_span() };
  Result.ok(VarDecl { mutable: !immutable, name: name, ty: ty, value: value, span: Span_new(start.start, end.end) })
}

fun Parser_parse_block(self: Parser) -> Any {
  let start = self.expect_kind(TokenKind.LBrace)?;
  let stmts = List.new();
  let tail = null;
  while (!self.check_kind(TokenKind.RBrace) && !self.at_eof()) {
    if self.check_keyword("let") || self.check_keyword("var") || self.check_keyword("return") ||
      self.check_keyword("break") || self.check_keyword("continue") || self.check_keyword("if") ||
      self.check_keyword("while") || self.check_keyword("for") || self.check_keyword("match") ||
      self.check_kind(TokenKind.LBrace) {
      stmts.push(self.parse_stmt()?);
      continue;
    }
    let expr = self.parse_expr()?;
    if (self.match_kind(TokenKind.Semi)) {
      stmts.push(Stmt.Expr(expr, self.prev_span()));
    } else {
      tail = expr;
      break;
    }
  }
  let end = self.expect_kind(TokenKind.RBrace)?;
  Result.ok(Block { stmts: stmts, tail: tail, span: Span_new(start.span.start, end.span.end) })
}

fun Parser_parse_expr(self: Parser) -> Any { self.parse_expr_bp(0) }

fun Parser_parse_expr_bp(self: Parser, min_bp: Int) -> Any {
  let lhs = self.parse_prefix()?;
  while (true) {
    if (self.match_kind(TokenKind.LParen)) {
      let args = List.new();
      if (!self.check_kind(TokenKind.RParen)) {
        args.push(self.parse_expr()?);
        while (self.match_kind(TokenKind.Comma)) { args.push(self.parse_expr()?); }
      }
      let end = self.expect_kind(TokenKind.RParen)?;
      let span = Span_new(self.span_of(lhs).start, end.span.end);
      lhs = Expr.Call(lhs, args, span);
      continue;
    }
    if (self.match_kind(TokenKind.Dot)) {
      let name = self.expect_ident()?;
      let span = Span_new(self.span_of(lhs).start, self.prev_span().end);
      lhs = Expr.Member(lhs, name, span);
      continue;
    }
    if (self.match_kind(TokenKind.LBracket)) {
      let index = self.parse_expr()?;
      let end = self.expect_kind(TokenKind.RBracket)?;
      let span = Span_new(self.span_of(lhs).start, end.span.end);
      lhs = Expr.Index(lhs, index, span);
      continue;
    }

    let infix = self.infix_binding_power();
    if (infix == null) { break; }
    let l_bp = infix.l_bp;
    let r_bp = infix.r_bp;
    let op = infix.op;
    if (l_bp < min_bp) { break; }
    self.advance();
    let rhs = self.parse_expr_bp(r_bp)?;
    let span = Span_new(self.span_of(lhs).start, self.span_of(rhs).end);
    lhs = match (op) {
      InfixOp.Binary(b) => Expr.Binary(lhs, b, rhs, span)
      InfixOp.Assign(a) => Expr.Assign(lhs, a, rhs, span)
    };
  }
  Result.ok(lhs)
}

fun Parser_parse_prefix(self: Parser) -> Any {
  let tok = self.current();
  match (tok.kind) {
    TokenKind.IntLiteral(v) => { self.advance(); Result.ok(Expr.Literal(Literal.Int(v), tok.span)) }
    TokenKind.FloatLiteral(v) => { self.advance(); Result.ok(Expr.Literal(Literal.Float(v), tok.span)) }
    TokenKind.StringLiteral(s) => {
      self.advance();
      if (self.check_kind(TokenKind.InterpStart)) {
        self.parse_interpolated_string(Expr.Literal(Literal.String(s), tok.span))
      } else {
        Result.ok(Expr.Literal(Literal.String(s), tok.span))
      }
    }
    TokenKind.CharLiteral(c) => { self.advance(); Result.ok(Expr.Literal(Literal.Char(c), tok.span)) }
    TokenKind.BoolLiteral(b) => { self.advance(); Result.ok(Expr.Literal(Literal.Bool(b), tok.span)) }
    TokenKind.Identifier(name) => {
      self.advance();
      if (name == "tensor" && self.check_kind(TokenKind.LBracket)) {
        return self.parse_tensor_literal(tok.span);
      }
      Result.ok(Expr.Ident(name, tok.span))
    }
    TokenKind.Keyword(k) => {
      if (k == "if") { return self.parse_if_expr(); }
      if (k == "match") { return self.parse_match_expr(); }
      if (k.starts_with("@")) {
        self.advance();
        Result.ok(Expr.Ident(k, tok.span))
      } else { self.error_at(tok.span, "unexpected token in expression"); Result.err(false) }
    }
    TokenKind.LParen => { self.advance(); let expr = self.parse_expr()?; self.expect_kind(TokenKind.RParen)?; Result.ok(expr) }
    TokenKind.LBracket => self.parse_array_literal()
    TokenKind.LBrace => { let block = self.parse_block()?; Result.ok(Expr.Block(block)) }
    TokenKind.Minus => {
      self.advance(); let expr = self.parse_expr_bp(70)?; let span = Span_new(tok.span.start, self.span_of(expr).end);
      Result.ok(Expr.Unary(UnaryOp.Neg, expr, span))
    }
    TokenKind.Plus => {
      self.advance(); let expr = self.parse_expr_bp(70)?; let span = Span_new(tok.span.start, self.span_of(expr).end);
      Result.ok(Expr.Unary(UnaryOp.Pos, expr, span))
    }
    TokenKind.Not => {
      self.advance(); let expr = self.parse_expr_bp(70)?; let span = Span_new(tok.span.start, self.span_of(expr).end);
      Result.ok(Expr.Unary(UnaryOp.Not, expr, span))
    }
    _ => { self.error_at(tok.span, "unexpected token in expression"); Result.err(false) }
  }
}

fun Parser_parse_if_expr(self: Parser) -> Any {
  let start = self.current_span();
  self.advance();
  let cond = self.parse_expr()?;
  let then_block = self.parse_block()?;
  self.expect_keyword("else")?;
  let else_block = self.parse_block()?;
  let span = Span_new(start.start, else_block.span.end);
  Result.ok(Expr.If(cond, then_block, else_block, span))
}

fun Parser_parse_match_expr(self: Parser) -> Any {
  let start = self.current_span();
  self.advance();
  let expr = self.parse_expr()?;
  let arms = self.parse_match_arms()?;
  let end = if (arms.len() > 0) { arms[arms.len() - 1].span.end } else { start.end };
  Result.ok(Expr.Match(expr, arms, Span_new(start.start, end)))
}

fun Parser_parse_match_arms(self: Parser) -> Any {
  self.expect_kind(TokenKind.LBrace)?;
  let arms = List.new();
  while (!self.check_kind(TokenKind.RBrace) && !self.at_eof()) {
    let pat = self.parse_pattern()?;
    self.expect_kind(TokenKind.FatArrow)?;
    let body = if (self.check_kind(TokenKind.LBrace)) { Expr.Block(self.parse_block()?) } else { self.parse_expr()? };
    let end = self.expect_kind(TokenKind.Semi)?;
    arms.push(MatchArm { pat: pat, body: body, span: Span_new(end.span.start, end.span.end) });
  }
  self.expect_kind(TokenKind.RBrace)?;
  Result.ok(arms)
}

fun Parser_parse_pattern(self: Parser) -> Any {
  let tok = self.current();
  match (tok.kind) {
    TokenKind.Identifier(name) => {
      self.advance();
      if (name == "_") { return Result.ok(Pattern.Wildcard(tok.span)); } self.advance(); Result.ok(Pattern.Wildcard(tok.span)) }
    TokenKind.Identifier(name) => {
      self.advance();
      if (self.match_kind(TokenKind.LBrace)) {
        let fields = List.new();
        if (!self.check_kind(TokenKind.RBrace)) {
          while (true) {
            let field = self.expect_ident()?;
            let pat = if (self.match_kind(TokenKind.Colon)) { self.parse_pattern()? } else { Pattern.Ident(field, self.prev_span()) };
            fields.push(FieldPattern { name: field, pat: pat });
            if (!self.match_kind(TokenKind.Comma)) { break; }
          }
        }
        let end = self.expect_kind(TokenKind.RBrace)?;
        return Result.ok(Pattern.Struct(name, fields, Span_new(tok.span.start, end.span.end)));
      }
      Result.ok(Pattern.Ident(name, tok.span))
    }
    TokenKind.IntLiteral(v) => { self.advance(); Result.ok(Pattern.Literal(Literal.Int(v), tok.span)) }
    TokenKind.FloatLiteral(v) => { self.advance(); Result.ok(Pattern.Literal(Literal.Float(v), tok.span)) }
    TokenKind.StringLiteral(s) => { self.advance(); Result.ok(Pattern.Literal(Literal.String(s), tok.span)) }
    TokenKind.CharLiteral(c) => { self.advance(); Result.ok(Pattern.Literal(Literal.Char(c), tok.span)) }
    TokenKind.BoolLiteral(b) => { self.advance(); Result.ok(Pattern.Literal(Literal.Bool(b), tok.span)) }
    TokenKind.LParen => {
      self.advance();
      let elems = List.new();
      if (!self.check_kind(TokenKind.RParen)) {
        elems.push(self.parse_pattern()?);
        while (self.match_kind(TokenKind.Comma)) { elems.push(self.parse_pattern()?); }
      }
      let end = self.expect_kind(TokenKind.RParen)?;
      Result.ok(Pattern.Tuple(elems, Span_new(tok.span.start, end.span.end)))
    }
    _ => { self.error_at(tok.span, "invalid pattern"); Result.err(false) }
  }
}

fun Parser_parse_array_literal(self: Parser) -> Any {
  let start = self.expect_kind(TokenKind.LBracket)?;
  let items = List.new();
  if (!self.check_kind(TokenKind.RBracket)) {
    items.push(self.parse_expr()?);
    while (self.match_kind(TokenKind.Comma)) { items.push(self.parse_expr()?); }
  }
  let end = self.expect_kind(TokenKind.RBracket)?;
  Result.ok(Expr.Array(items, Span_new(start.span.start, end.span.end)))
}

fun Parser_parse_tensor_literal(self: Parser, start: Span) -> Any {
  self.expect_kind(TokenKind.LBracket)?;
  let rows = List.new();
  if (!self.check_kind(TokenKind.RBracket)) {
    rows.push(self.parse_tensor_row()?);
    while (self.match_kind(TokenKind.Comma)) { rows.push(self.parse_tensor_row()?); }
  }
  let end = self.expect_kind(TokenKind.RBracket)?;
  Result.ok(Expr.Tensor(rows, Span_new(start.start, end.span.end)))
}

fun Parser_parse_tensor_row(self: Parser) -> Any {
  self.expect_kind(TokenKind.LBracket)?;
  let row = List.new();
  if (!self.check_kind(TokenKind.RBracket)) {
    row.push(self.parse_expr()?);
    while (self.match_kind(TokenKind.Comma)) { row.push(self.parse_expr()?); }
  }
  self.expect_kind(TokenKind.RBracket)?;
  Result.ok(row)
}

fun Parser_parse_interpolated_string(self: Parser, first: Expr) -> Any {
  let parts = List.new();
  parts.push(first);
  while (self.match_kind(TokenKind.InterpStart)) {
    let expr = self.parse_expr()?;
    self.expect_kind(TokenKind.InterpEnd)?;
    parts.push(expr);
    if (self.current().kind.is_string_literal()) {
      let span = self.current().span;
      let s = self.current().kind.string_value();
      self.advance();
      parts.push(Expr.Literal(Literal.String(s), span));
    } else {
      break;
    }
  }
  let span = Span_new(self.span_of(parts[0]).start, self.span_of(parts[parts.len() - 1]).end);
  Result.ok(Expr.Interpolated(parts, span))
}

fun Parser_parse_type_ref(self: Parser) -> Any {
  let base = if (self.match_kind(TokenKind.LParen)) {
    let start = self.prev_span();
    let elems = List.new();
    if (!self.check_kind(TokenKind.RParen)) {
      elems.push(self.parse_type_ref()?);
      while (self.match_kind(TokenKind.Comma)) { elems.push(self.parse_type_ref()?); }
    }
    let end = self.expect_kind(TokenKind.RParen)?;
    TypeRef.Tuple(elems, Span_new(start.start, end.span.end))
  } else if (self.match_kind(TokenKind.LBracket)) {
    let start = self.prev_span();
    let inner = self.parse_type_ref()?;
    let end = self.expect_kind(TokenKind.RBracket)?;
    TypeRef.Array(inner, Span_new(start.start, end.span.end))
  } else {
    let name = self.parse_qualified_ident()?;
    let span = self.prev_span();
    if (name == "Tensor" && self.match_kind(TokenKind.Lt)) {
      let elem = self.parse_type_ref()?;
      self.expect_kind(TokenKind.Comma)?;
      let shape = self.parse_shape_ref()?;
      let end = self.expect_kind(TokenKind.Gt)?;
      TypeRef.Tensor(elem, shape, Span_new(span.start, end.span.end))
    } else if (self.match_kind(TokenKind.Lt)) { 
      let args = List.new();
      args.push(self.parse_type_ref()?);
      while (self.match_kind(TokenKind.Comma)) { args.push(self.parse_type_ref()?); }
      let end = self.expect_kind(TokenKind.Gt)?;
      TypeRef.Named(name, args, Span_new(span.start, end.span.end))
    } else {
      TypeRef.Named(name, List.new(), span)
    }
  };

  if (self.match_kind(TokenKind.Question)) {
    let span = self.prev_span();
    Result.ok(TypeRef.Optional(base, span))
  } else if (self.match_kind(TokenKind.Not)) {
    let span = self.prev_span();
    Result.ok(TypeRef.NonNull(base, span))
  } else {
    Result.ok(base)
  }
}

fun Parser_parse_shape_ref(self: Parser) -> Any {
  self.expect_kind(TokenKind.LBracket)?;
  let dims = List.new();
  if (!self.check_kind(TokenKind.RBracket)) {
    dims.push(self.parse_shape_dim()?);
    while (self.match_kind(TokenKind.Comma)) { dims.push(self.parse_shape_dim()?); }
  }
  self.expect_kind(TokenKind.RBracket)?;
  Result.ok(dims)
}

fun Parser_parse_shape_dim(self: Parser) -> Any {
  let tok = self.current();
  match (tok.kind) {
    TokenKind.IntLiteral(v) => { self.advance(); Result.ok(ShapeDim.Int(v)) }
    TokenKind.Identifier(name) => { self.advance(); Result.ok(if (name == "_") { ShapeDim.Unknown } else { ShapeDim.Ident(name) }) }
    _ => { self.error_at(tok.span, "invalid shape dimension"); Result.err(false) }
  }
}

fun Parser_parse_param_list(self: Parser) -> Any {
  self.expect_kind(TokenKind.LParen)?;
  let params = List.new();
  if (!self.check_kind(TokenKind.RParen)) {
    params.push(self.parse_param()?);
    while (self.match_kind(TokenKind.Comma)) { params.push(self.parse_param()?); }
  }
  self.expect_kind(TokenKind.RParen)?;
  Result.ok(params)
}

fun Parser_parse_param(self: Parser) -> Any {
  let start = self.current_span();
  let name = self.expect_ident()?;
  self.expect_kind(TokenKind.Colon)?;
  let ty = self.parse_type_ref()?;
  Result.ok(Param { name: name, ty: ty, span: Span_new(start.start, self.prev_span().end) })
}

fun Parser_parse_qualified_ident(self: Parser) -> Any {
  let name = self.expect_ident()?;
  while (self.match_kind(TokenKind.Dot)) {
    let part = self.expect_ident()?;
    name = name + "." + part;
  }
  Result.ok(name)
}

fun Parser_infix_binding_power(self: Parser) -> InfixPower? {
  let k = self.current().kind;
  if (k == TokenKind.Star) { return InfixPower { l_bp: 60, r_bp: 61, op: InfixOp.Binary(BinaryOp.Mul) }; }
  if (k == TokenKind.Slash) { return InfixPower { l_bp: 60, r_bp: 61, op: InfixOp.Binary(BinaryOp.Div) }; }
  if (k == TokenKind.Percent) { return InfixPower { l_bp: 60, r_bp: 61, op: InfixOp.Binary(BinaryOp.Mod) }; }
  if (k == TokenKind.DotStar) { return InfixPower { l_bp: 60, r_bp: 61, op: InfixOp.Binary(BinaryOp.DotMul) }; }
  if (k == TokenKind.DotSlash) { return InfixPower { l_bp: 60, r_bp: 61, op: InfixOp.Binary(BinaryOp.DotDiv) }; }
  if (k == TokenKind.At) { return InfixPower { l_bp: 60, r_bp: 61, op: InfixOp.Binary(BinaryOp.MatMul) }; }
  if (k == TokenKind.Plus) { return InfixPower { l_bp: 50, r_bp: 51, op: InfixOp.Binary(BinaryOp.Add) }; }
  if (k == TokenKind.Minus) { return InfixPower { l_bp: 50, r_bp: 51, op: InfixOp.Binary(BinaryOp.Sub) }; }
  if (k == TokenKind.DotPlus) { return InfixPower { l_bp: 50, r_bp: 51, op: InfixOp.Binary(BinaryOp.DotAdd) }; }
  if (k == TokenKind.DotMinus) { return InfixPower { l_bp: 50, r_bp: 51, op: InfixOp.Binary(BinaryOp.DotSub) }; }
  if (k == TokenKind.Lt) { return InfixPower { l_bp: 40, r_bp: 41, op: InfixOp.Binary(BinaryOp.Lt) }; }
  if (k == TokenKind.LtEq) { return InfixPower { l_bp: 40, r_bp: 41, op: InfixOp.Binary(BinaryOp.LtEq) }; }
  if (k == TokenKind.Gt) { return InfixPower { l_bp: 40, r_bp: 41, op: InfixOp.Binary(BinaryOp.Gt) }; }
  if (k == TokenKind.GtEq) { return InfixPower { l_bp: 40, r_bp: 41, op: InfixOp.Binary(BinaryOp.GtEq) }; }
  if (k == TokenKind.EqEq) { return InfixPower { l_bp: 35, r_bp: 36, op: InfixOp.Binary(BinaryOp.Eq) }; }
  if (k == TokenKind.NotEq) { return InfixPower { l_bp: 35, r_bp: 36, op: InfixOp.Binary(BinaryOp.NotEq) }; }
  if (k == TokenKind.AndAnd) { return InfixPower { l_bp: 30, r_bp: 31, op: InfixOp.Binary(BinaryOp.And) }; }
  if (k == TokenKind.OrOr) { return InfixPower { l_bp: 25, r_bp: 26, op: InfixOp.Binary(BinaryOp.Or) }; }
  if (k == TokenKind.NullCoalesce) { return InfixPower { l_bp: 20, r_bp: 20, op: InfixOp.Binary(BinaryOp.NullCoalesce) }; }
  if (k == TokenKind.Pipe) { return InfixPower { l_bp: 15, r_bp: 16, op: InfixOp.Binary(BinaryOp.Pipe) }; }
  if (k == TokenKind.Arrow) { return InfixPower { l_bp: 15, r_bp: 16, op: InfixOp.Binary(BinaryOp.Arrow) }; }
  if (k == TokenKind.Eq) { return InfixPower { l_bp: 10, r_bp: 10, op: InfixOp.Assign(AssignOp.Assign) }; }
  if (k == TokenKind.PlusEq) { return InfixPower { l_bp: 10, r_bp: 10, op: InfixOp.Assign(AssignOp.AddAssign) }; }
  if (k == TokenKind.MinusEq) { return InfixPower { l_bp: 10, r_bp: 10, op: InfixOp.Assign(AssignOp.SubAssign) }; }
  if (k == TokenKind.StarEq) { return InfixPower { l_bp: 10, r_bp: 10, op: InfixOp.Assign(AssignOp.MulAssign) }; }
  if (k == TokenKind.SlashEq) { return InfixPower { l_bp: 10, r_bp: 10, op: InfixOp.Assign(AssignOp.DivAssign) }; }
  if (k == TokenKind.PercentEq) { return InfixPower { l_bp: 10, r_bp: 10, op: InfixOp.Assign(AssignOp.ModAssign) }; }
  null
}

fun Parser_current(self: Parser) -> Token { self.tokens[self.pos] }
fun Parser_current_span(self: Parser) -> Span { self.current().span }
fun Parser_prev_span(self: Parser) -> Span {
  let idx = if (self.pos > 0) { self.pos - 1 } else { 0 };
  self.tokens[idx].span
}

fun Parser_span_of(self: Parser, expr: Expr) -> Span {
  match (expr) {
    Expr.Literal(_, s) => s
    Expr.Ident(_, s) => s
    Expr.Unary(_, _, s) => s
    Expr.Binary(_, _, _, s) => s
    Expr.Assign(_, _, _, s) => s
    Expr.Call(_, _, s) => s
    Expr.Member(_, _, s) => s
    Expr.Index(_, _, s) => s
    Expr.If(_, _, _, s) => s
    Expr.Match(_, _, s) => s
    Expr.Block(b) => b.span
    Expr.Array(_, s) => s
    Expr.Tensor(_, s) => s
    Expr.Interpolated(_, s) => s
  }
}

fun Parser_advance(self: Parser) -> Token {
  if (!self.at_eof()) { self.pos = self.pos + 1; }
  self.tokens[self.pos - 1]
}

fun Parser_at_eof(self: Parser) -> Bool { self.current().kind == TokenKind.Eof }

fun Parser_check_kind(self: Parser, kind: TokenKind) -> Bool { self.current().kind == kind }

fun Parser_peek_kind(self: Parser, kind: TokenKind) -> Bool {
  if (self.pos + 1 >= self.tokens.len()) { false } else { self.tokens[self.pos + 1].kind == kind }
}

fun Parser_match_kind(self: Parser, kind: TokenKind) -> Bool {
  if (self.check_kind(kind)) { self.advance(); true } else { false }
}

fun Parser_match_keyword(self: Parser, kw: String) -> Bool {
  if (self.check_keyword(kw)) { self.advance(); true } else { false }
}

fun Parser_check_keyword(self: Parser, kw: String) -> Bool {
  self.current().kind.is_keyword(kw)
}

fun Parser_expect_keyword(self: Parser, kw: String) -> Any {
  if (self.check_keyword(kw)) { self.advance(); Result.ok(true) } else { self.error("expected keyword '" + kw + "'"); Result.err(false) }
}

fun Parser_expect_kind(self: Parser, kind: TokenKind) -> Any {
  if (self.check_kind(kind)) { Result.ok(self.advance()) } else { self.error("expected token"); Result.err(false) }
}

fun Parser_expect_ident(self: Parser) -> Any {
  let k = self.current().kind;
  if (k.is_identifier()) {
    let name = k.ident_value();
    self.advance();
    Result.ok(name)
  } else {
    self.error("expected identifier");
    Result.err(false)
  }
}

fun Parser_error(self: Parser, msg: String) {
  let span = self.current_span();
  self.diags.push(Diagnostic_new(msg, span));
}

fun Parser_error_at(self: Parser, span: Span, msg: String) {
  self.diags.push(Diagnostic_new(msg, span));
}

fun Parser_synchronize(self: Parser) {
  while (!self.at_eof()) {
    let k = self.current().kind;
    if (k == TokenKind.Semi || k == TokenKind.RBrace) { self.advance(); break; }
    if (self.check_keyword("fun") 
        || self.check_keyword("gpu") 
        || self.check_keyword("struct") 
        || self.check_keyword("enum") 
        || self.check_keyword("type") 
        || self.check_keyword("view") 
        || self.check_keyword("resource") 
        || self.check_keyword("let") 
        || self.check_keyword("var") 
        || self.check_keyword("if") 
        || self.check_keyword("while") 
        || self.check_keyword("for") 
        || self.check_keyword("match") 
        || self.check_keyword("return")) {
      break;
    }
    self.advance();
  }
}

fun Parser_parse_attributes(self: Parser) -> Any {
  let attrs = List.new();
  while (self.check_kind(TokenKind.At)) {
    let start = self.advance().span;
    let name = self.expect_ident()?;
    let args = List.new();
    if (self.match_kind(TokenKind.LParen)) {
      if (!self.check_kind(TokenKind.RParen)) {
        args.push(self.parse_expr()?);
        while (self.match_kind(TokenKind.Comma)) { args.push(self.parse_expr()?); }
      }
      self.expect_kind(TokenKind.RParen)?;
    }
    attrs.push(Attribute { name: name, args: args, span: Span_new(start.start, self.prev_span().end) });
  }
  Result.ok(attrs)
}
// Self-hosted semantic analysis: type inference + unification



struct Constraint {
  left: Type;
  right: Type;
  span: Span;
}

struct Subst {
  id: Int;
  ty: Type;
}

struct InferCtx {
  next_var: Int;
  constraints: Any;
  subs: Any;
  symtab: SymbolTable;
}

fun infer_program(prog: Program) -> Any

// internal helpers
fun infer_item(ctx: InferCtx, item: Item, diags: Any)
fun infer_fun(ctx: InferCtx, f: FunDecl, diags: Any)
fun infer_stmt(ctx: InferCtx, stmt: Stmt, diags: Any) -> Type
fun infer_block(ctx: InferCtx, block: Block, diags: Any) -> Type
fun infer_expr(ctx: InferCtx, expr: Expr, diags: Any) -> Type
fun infer_pattern(ctx: InferCtx, pat: Pattern, diags: Any) -> Type

fun fresh_var(ctx: InferCtx) -> Type
fun add_constraint(ctx: InferCtx, a: Type, b: Type, span: Span)
fun unify_all(ctx: InferCtx, diags: Any)
fun unify(ctx: InferCtx, a: Type, b: Type, span: Span, diags: Any)
fun resolve(ctx: InferCtx, t: Type) -> Type
fun occurs(id: Int, t: Type, ctx: InferCtx) -> Bool

fun is_number(t: Type) -> Bool

fun infer_program(prog: Program) -> Any {
  let diags = List.new();
  let ctx = InferCtx {
    next_var: 0,
    constraints: List.new(),
    subs: List.new(),
    symtab: SymbolTable_new(),
  };

  // Predefine function signatures.
  let i = 0;
  while (i < prog.items.len()) {
    match (prog.items[i]) {
      Item.Fun(f, _, vis) => {
        let params = List.new();
        let j = 0;
        while (j < f.params.len()) {
          params.push(type_from_ref(f.params[j].ty));
          j = j + 1;
        }
        let ret = if (f.ret != null) { type_from_ref(f.ret) } else { Type.Unit };
        ctx.symtab.define(f.name, Type.Func(params, ret), false, SymbolKind.Func, vis);
      }
      Item.Struct(s, _, vis) => {
        ctx.symtab.define(s.name, Type.Named(s.name, List.new(), s.span), false, SymbolKind.Struct, vis);
      }
      Item.Enum(e, _, vis) => {
        ctx.symtab.define(e.name, Type.Named(e.name, List.new(), e.span), false, SymbolKind.Enum, vis);
      }
      _ => {}
    }
    i = i + 1;
  }

  let k = 0;
  while (k < prog.items.len()) {
    infer_item(ctx, prog.items[k], diags);
    k = k + 1;
  }

  unify_all(ctx, diags);

  if (diags.len() == 0) { Result.ok(prog) } else { Result.err(diags) }
}

fun infer_item(ctx: InferCtx, item: Item, diags: Any) {
  match (item) {
    Item.Fun(f, _, _) => infer_fun(ctx, f, diags)
    Item.Const(v, _, vis) => {
      let ty = infer_expr(ctx, v.value, diags);
      if (v.ty != null) { add_constraint(ctx, type_from_ref(v.ty), ty, v.span); }
      ctx.symtab.define(v.name, ty, v.mutable, SymbolKind.Var, vis);
    }
    Item.Stmt(s) => { infer_stmt(ctx, s, diags); }
    _ => {}
  }
}

fun infer_fun(ctx: InferCtx, f: FunDecl, diags: Any) {
  ctx.symtab.enter();
  let i = 0;
  while (i < f.params.len()) {
    let p = f.params[i];
    ctx.symtab.define(p.name, type_from_ref(p.ty), false, SymbolKind.Var, Visibility.Private);
    i = i + 1;
  }
  let body_ty = infer_block(ctx, f.body, diags);
  if (f.ret != null) {
    add_constraint(ctx, type_from_ref(f.ret), body_ty, f.span);
  }
  ctx.symtab.exit();
}

fun infer_stmt(ctx: InferCtx, stmt: Stmt, diags: Any) -> Type {
  match (stmt) {
    Stmt.Var(v) => {
      let ty = infer_expr(ctx, v.value, diags);
      if (v.ty != null) { add_constraint(ctx, type_from_ref(v.ty), ty, v.span); }
      ctx.symtab.define(v.name, ty, v.mutable, SymbolKind.Var, Visibility.Private);
      Type.Unit
    }
    Stmt.Expr(e, _) => { infer_expr(ctx, e, diags); Type.Unit }
    Stmt.Return(e, _) => { if (e != null) { infer_expr(ctx, e, diags) } else { Type.Unit } }
    Stmt.Break(_) => Type.Nothing
    Stmt.Continue(_) => Type.Nothing
    Stmt.If(cond, then_block, else_stmt, span) => {
      let ct = infer_expr(ctx, cond, diags);
      add_constraint(ctx, Type.Bool, ct, span);
      let tt = infer_block(ctx, then_block, diags);
      let et = if (else_stmt != null) {
        match (else_stmt) {
          Stmt.Block(b) => infer_block(ctx, b, diags)
          _ => infer_stmt(ctx, else_stmt, diags)
        }
      } else { Type.Unit };
      if (tt == et) { tt } else { Type.Any }
    }
    Stmt.While(cond, body, span) => {
      let ct = infer_expr(ctx, cond, diags);
      add_constraint(ctx, Type.Bool, ct, span);
      infer_block(ctx, body, diags);
      Type.Unit
    }
    Stmt.For(name, iter, body, span) => {
      let it = infer_expr(ctx, iter, diags);
      let elem = match (it) {
        Type.Array(inner) => inner
        _ => { diags.push(Diagnostic_new("for-in expects array", span)); Type.Unknown }
      };
      ctx.symtab.enter();
      ctx.symtab.define(name, elem, false, SymbolKind.Var, Visibility.Private);
      infer_block(ctx, body, diags);
      ctx.symtab.exit();
      Type.Unit
    }
    Stmt.Match(expr, arms, _) => {
      let _ = infer_expr(ctx, expr, diags);
      let ty = Type.Unknown;
      let i = 0;
      while (i < arms.len()) {
        let at = infer_expr(ctx, arms[i].body, diags);
        ty = if (ty == Type.Unknown) { at } else if (ty == at) { ty } else { Type.Any };
        i = i + 1;
      }
      ty
    }
    Stmt.Block(b) => infer_block(ctx, b, diags)
  }
}

fun infer_block(ctx: InferCtx, block: Block, diags: Any) -> Type {
  ctx.symtab.enter();
  let i = 0;
  while (i < block.stmts.len()) {
    infer_stmt(ctx, block.stmts[i], diags);
    i = i + 1;
  }
  let ty = if (block.tail != null) { infer_expr(ctx, block.tail, diags) } else { Type.Unit };
  ctx.symtab.exit();
  ty
}

fun infer_expr(ctx: InferCtx, expr: Expr, diags: Any) -> Type {
  match (expr) {
    Expr.Literal(l, _) => match (l) {
      Literal.Int(_) => Type.Int
      Literal.Float(_) => Type.Float
      Literal.String(_) => Type.String
      Literal.Char(_) => Type.Char
      Literal.Bool(_) => Type.Bool
    }
    Expr.Ident(name, span) => {
      let sym = ctx.symtab.lookup(name);
      if (sym == null) { diags.push(Diagnostic_new("undefined symbol '" + name + "'", span)); return Type.Unknown; }
      sym.ty
    }
    Expr.Unary(op, e, span) => {
      let t = infer_expr(ctx, e, diags);
      match (op) {
        UnaryOp.Not => { add_constraint(ctx, Type.Bool, t, span); Type.Bool }
        UnaryOp.Neg => { if (!is_number(t)) { add_constraint(ctx, Type.Number, t, span); } Type.Float }
        UnaryOp.Pos => { if (!is_number(t)) { add_constraint(ctx, Type.Number, t, span); } Type.Float }
        UnaryOp.BitNot => { add_constraint(ctx, Type.Int, t, span); Type.Int }
      }
    }
    Expr.Binary(left, op, right, span) => {
      let lt = infer_expr(ctx, left, diags);
      let rt = infer_expr(ctx, right, diags);
      if (op == BinaryOp.Add || op == BinaryOp.Sub || op == BinaryOp.Mul || op == BinaryOp.Div || op == BinaryOp.Mod) {
        add_constraint(ctx, Type.Number, lt, span);
        add_constraint(ctx, Type.Number, rt, span);
        if (lt == rt) { lt } else { Type.Float }
      } else if (op == BinaryOp.DotAdd || op == BinaryOp.DotSub || op == BinaryOp.DotMul || op == BinaryOp.DotDiv || op == BinaryOp.MatMul) {
        Type.Tensor(Type.Float)
      } else if (op == BinaryOp.Eq || op == BinaryOp.NotEq || op == BinaryOp.Lt || op == BinaryOp.LtEq || op == BinaryOp.Gt || op == BinaryOp.GtEq) {
        Type.Bool
      } else if (op == BinaryOp.And || op == BinaryOp.Or) {
        add_constraint(ctx, Type.Bool, lt, span);
        add_constraint(ctx, Type.Bool, rt, span);
        Type.Bool
      } else if (op == BinaryOp.NullCoalesce) {
        if (lt == rt) { lt } else { Type.Any }
      } else {
        rt
      }
    }
    Expr.Assign(left, _, right, span) => {
      let lt = infer_expr(ctx, left, diags);
      let rt = infer_expr(ctx, right, diags);
      add_constraint(ctx, lt, rt, span);
      lt
    }
    Expr.Call(callee, args, span) => {
      let ct = infer_expr(ctx, callee, diags);
      match (ct) {
        Type.Func(params, ret) => {
          let i = 0;
          while (i < args.len()) {
            let at = infer_expr(ctx, args[i], diags);
            if (i < params.len()) { add_constraint(ctx, params[i], at, span); }
            i = i + 1;
          }
          ret
        }
        _ => { diags.push(Diagnostic_new("call to non-function", span)); Type.Unknown }
      }
    }
    Expr.Member(target, _, _) => { infer_expr(ctx, target, diags); Type.Unknown }
    Expr.Index(target, index, span) => {
      let t = infer_expr(ctx, target, diags);
      let _ = infer_expr(ctx, index, diags);
      match (t) {
        Type.Array(inner) => inner
        _ => { diags.push(Diagnostic_new("indexing non-array", span)); Type.Unknown }
      }
    }
    Expr.If(cond, then_block, else_block, span) => {
      let ct = infer_expr(ctx, cond, diags);
      add_constraint(ctx, Type.Bool, ct, span);
      let tt = infer_block(ctx, then_block, diags);
      let et = infer_block(ctx, else_block, diags);
      if (tt == et) { tt } else { Type.Any }
    }
    Expr.Match(expr, arms, _) => {
      let _ = infer_expr(ctx, expr, diags);
      let ty = Type.Unknown;
      let i = 0;
      while (i < arms.len()) {
        let at = infer_expr(ctx, arms[i].body, diags);
        ty = if (ty == Type.Unknown) { at } else if (ty == at) { ty } else { Type.Any };
        i = i + 1;
      }
      ty
    }
    Expr.Block(b) => infer_block(ctx, b, diags)
    Expr.Array(items, span) => {
      let elem = Type.Unknown;
      let i = 0;
      while (i < items.len()) {
        let t = infer_expr(ctx, items[i], diags);
        elem = if (elem == Type.Unknown) { t } else if (elem == t) { elem } else { Type.Any };
        i = i + 1;
      }
      Type.Array(elem)
    }
    Expr.Tensor(_, _) => Type.Tensor(Type.Float)
    Expr.Interpolated(parts, _) => { let i = 0; while (i < parts.len()) { infer_expr(ctx, parts[i], diags); i = i + 1; } Type.String }
  }
}

fun infer_pattern(ctx: InferCtx, pat: Pattern, diags: Any) -> Type {
  match (pat) {
    Pattern.Ident(_, _) => fresh_var(ctx)
    Pattern.Wildcard(_) => fresh_var(ctx)
    Pattern.Literal(l, _) => match (l) {
      Literal.Int(_) => Type.Int
      Literal.Float(_) => Type.Float
      Literal.String(_) => Type.String
      Literal.Char(_) => Type.Char
      Literal.Bool(_) => Type.Bool
    }
    Pattern.Tuple(ps, _) => {
      let tys = List.new();
      let i = 0;
      while (i < ps.len()) { tys.push(infer_pattern(ctx, ps[i], diags)); i = i + 1; }
      Type.Tuple(tys)
    }
    Pattern.Struct(_, _, _) => fresh_var(ctx)
  }
}

fun fresh_var(ctx: InferCtx) -> Type {
  let id = ctx.next_var;
  ctx.next_var = ctx.next_var + 1;
  Type.Var(id)
}

fun add_constraint(ctx: InferCtx, a: Type, b: Type, span: Span) {
  ctx.constraints.push(Constraint { left: a, right: b, span: span });
}

fun unify_all(ctx: InferCtx, diags: Any) {
  let i = 0;
  while (i < ctx.constraints.len()) {
    let c = ctx.constraints[i];
    unify(ctx, c.left, c.right, c.span, diags);
    i = i + 1;
  }
}

fun unify(ctx: InferCtx, a: Type, b: Type, span: Span, diags: Any) {
  let ra = resolve(ctx, a);
  let rb = resolve(ctx, b);

  if (ra == rb) { return; }

  match (ra) {
    Type.Var(id) => {
      if (occurs(id, rb, ctx)) { diags.push(Diagnostic_new("recursive type", span)); return; }
      ctx.subs.push(Subst { id: id, ty: rb });
      return;
    }
    _ => {}
  }

  match (rb) {
    Type.Var(id) => {
      if (occurs(id, ra, ctx)) { diags.push(Diagnostic_new("recursive type", span)); return; }
      ctx.subs.push(Subst { id: id, ty: ra });
      return;
    }
    _ => {}
  }

  if (ra == Type.Number && is_number(rb)) { return; }
  if (rb == Type.Number && is_number(ra)) { return; }

  match (ra) {
    Type.Tuple(ae) => match (rb) { Type.Tuple(be) => {
      if (ae.len() != be.len()) { diags.push(Diagnostic_new("tuple length mismatch", span)); return; }
      let i = 0; while (i < ae.len()) { unify(ctx, ae[i], be[i], span, diags); i = i + 1; }
      return;
    } _ => {} }
    Type.Array(at) => match (rb) { Type.Array(bt) => { unify(ctx, at, bt, span, diags); return; } _ => {} }
    Type.Tensor(at) => match (rb) { Type.Tensor(bt) => { unify(ctx, at, bt, span, diags); return; } _ => {} }
    Type.Func(ap, ar) => match (rb) { Type.Func(bp, br) => {
      if (ap.len() != bp.len()) { diags.push(Diagnostic_new("function arity mismatch", span)); return; }
      let i = 0; while (i < ap.len()) { unify(ctx, ap[i], bp[i], span, diags); i = i + 1; }
      unify(ctx, ar, br, span, diags);
      return;
    } _ => {} }
    _ => {}
  }

  diags.push(Diagnostic_new("type mismatch", span));
}

fun resolve(ctx: InferCtx, t: Type) -> Type {
  match (t) {
    Type.Var(id) => {
      let i = 0;
      while (i < ctx.subs.len()) {
        if (ctx.subs[i].id == id) { return resolve(ctx, ctx.subs[i].ty); }
        i = i + 1;
      }
      t
    }
    Type.Array(inner) => Type.Array(resolve(ctx, inner))
    Type.Tensor(inner) => Type.Tensor(resolve(ctx, inner))
    Type.Tuple(elems) => {
      let out = List.new();
      let i = 0; while (i < elems.len()) { out.push(resolve(ctx, elems[i])); i = i + 1; }
      Type.Tuple(out)
    }
    Type.Func(params, ret) => {
      let out = List.new();
      let i = 0; while (i < params.len()) { out.push(resolve(ctx, params[i])); i = i + 1; }
      Type.Func(out, resolve(ctx, ret))
    }
    _ => t
  }
}

fun occurs(id: Int, t: Type, ctx: InferCtx) -> Bool {
  let r = resolve(ctx, t);
  match (r) {
    Type.Var(v) => v == id
    Type.Array(inner) => occurs(id, inner, ctx)
    Type.Tensor(inner) => occurs(id, inner, ctx)
    Type.Tuple(elems) => { let i = 0; while (i < elems.len()) { if (occurs(id, elems[i], ctx)) { return true; } i = i + 1; } false }
    Type.Func(params, ret) => {
      let i = 0; while (i < params.len()) { if (occurs(id, params[i], ctx)) { return true; } i = i + 1; }
      occurs(id, ret, ctx)
    }
    _ => false
  }
}

fun is_number(t: Type) -> Bool {
  t == Type.Int || t == Type.UInt || t == Type.Float
}
// Self-hosted compiler IR: KIR definitions and lowering



struct KirModule {
  functions: Any;
}

struct KirFunction {
  name: String;
  params: Any;
  ret: KirType;
  blocks: Any;
}

struct KirParam {
  name: String;
  ty: KirType;
}

struct KirBlock {
  label: String;
  instrs: Any;
}

enum KirInstr {
  Let(String, KirType, KirValue);
  Assign(String, KirValue);
  Return(KirValue?);
  Branch(String);
  CondBranch(KirValue, String, String);
  Call(String, Any);
  Phi(String, KirType, Any);
  Load(KirValue);
  Store(KirValue, KirValue);
  Borrow(KirValue);
  Move(KirValue);
  Drop(KirValue);
}

enum KirValue {
  Reg(String, KirType);
  Const(Literal, KirType);
}

enum KirType {
  Int;
  UInt;
  Float;
  Bool;
  Char;
  String;
  Ptr(KirType);
  Array(KirType);
  Tuple(Any);
  Struct(String);
  Void;
}

struct Binding {
  name: String;
  reg: String;
  ty: KirType;
}

struct LowerCtx {
  next_reg: Int;
  bindings: Any;
  blocks: Any;
  current: Int;
}

fun lower_program(prog: Program) -> KirModule

// internal
fun lower_fun(f: FunDecl) -> KirFunction
fun lower_block(ctx: LowerCtx, block: Block)
fun lower_stmt(ctx: LowerCtx, stmt: Stmt)
fun lower_expr(ctx: LowerCtx, expr: Expr) -> KirValue
fun kir_type_from(t: Type) -> KirType
fun new_reg(ctx: LowerCtx) -> String
fun bind(ctx: LowerCtx, name: String, reg: String, ty: KirType)
fun lookup(ctx: LowerCtx, name: String) -> KirValue
fun current_block(ctx: LowerCtx) -> KirBlock
fun push_instr(ctx: LowerCtx, instr: KirInstr)

fun lower_program(prog: Program) -> KirModule {
  let funs = List.new();
  let i = 0;
  while (i < prog.items.len()) {
    match (prog.items[i]) {
      Item.Fun(f) => funs.push(lower_fun(f))
      _ => {}
    }
    i = i + 1;
  }
  KirModule { functions: funs }
}

fun lower_fun(f: FunDecl) -> KirFunction {
  let params = List.new();
  let i = 0;
  while (i < f.params.len()) {
    let p = f.params[i];
    params.push(KirParam { name: p.name, ty: kir_type_from(type_from_ref(p.ty)) });
    i = i + 1;
  }

  let ctx = LowerCtx {
    next_reg: 0,
    bindings: List.new(),
    blocks: List.new(),
    current: 0,
  };
  ctx.blocks.push(KirBlock { label: "entry", instrs: List.new() });

  let j = 0;
  while (j < params.len()) {
    bind(ctx, params[j].name, params[j].name, params[j].ty);
    j = j + 1;
  }

  lower_block(ctx, f.body);

  KirFunction {
    name: f.name,
    params: params,
    ret: if (f.ret != null) { kir_type_from(type_from_ref(f.ret)) } else { KirType.Void },
    blocks: ctx.blocks,
  }
}

fun lower_block(ctx: LowerCtx, block: Block) {
  let i = 0;
  while (i < block.stmts.len()) {
    lower_stmt(ctx, block.stmts[i]);
    i = i + 1;
  }
  if (block.tail != null) {
    let v = lower_expr(ctx, block.tail);
    push_instr(ctx, KirInstr.Return(v));
  }
}

fun lower_stmt(ctx: LowerCtx, stmt: Stmt) {
  match (stmt) {
    Stmt.Var(v) => {
      let val = lower_expr(ctx, v.value);
      let reg = new_reg(ctx);
      push_instr(ctx, KirInstr.Let(reg, val.ty(), val));
      bind(ctx, v.name, reg, val.ty());
    }
    Stmt.Expr(e, _) => { let _ = lower_expr(ctx, e); }
    Stmt.Return(e, _) => {
      if (e != null) { push_instr(ctx, KirInstr.Return(lower_expr(ctx, e))); }
      else { push_instr(ctx, KirInstr.Return(null)); }
    }
    Stmt.Block(b) => { lower_block(ctx, b); }
    _ => {}
  }
}

fun lower_expr(ctx: LowerCtx, expr: Expr) -> KirValue {
  match (expr) {
    Expr.Literal(l, _) => {
      let t = match (l) {
        Literal.Int(_) => KirType.Int
        Literal.Float(_) => KirType.Float
        Literal.String(_) => KirType.String
        Literal.Char(_) => KirType.Char
        Literal.Bool(_) => KirType.Bool
      };
      KirValue.Const(l, t)
    }
    Expr.Ident(name, _) => lookup(ctx, name)
    Expr.Binary(left, _, right, _) => {
      let _ = lower_expr(ctx, left);
      let r = lower_expr(ctx, right);
      r
    }
    Expr.Assign(left, _, right, _) => {
      let r = lower_expr(ctx, right);
      match (left) {
        Expr.Ident(name, _) => {
          let reg = lookup(ctx, name);
          push_instr(ctx, KirInstr.Assign(reg.reg_name(), r));
          reg
        }
        _ => r
      }
    }
    Expr.Call(callee, args, _) => {
      let call_args = List.new();
      let i = 0; while (i < args.len()) { call_args.push(lower_expr(ctx, args[i])); i = i + 1; }
      let name = match (callee) { Expr.Ident(n, _) => n _ => "" };
      push_instr(ctx, KirInstr.Call(name, call_args));
      KirValue.Reg(new_reg(ctx), KirType.Int)
    }
    Expr.Array(items, _) => {
      let i = 0; while (i < items.len()) { lower_expr(ctx, items[i]); i = i + 1; }
      KirValue.Reg(new_reg(ctx), KirType.Array(KirType.Int))
    }
    Expr.Block(b) => { lower_block(ctx, b); KirValue.Reg(new_reg(ctx), KirType.Int) }
    _ => KirValue.Reg(new_reg(ctx), KirType.Int)
  }
}

fun kir_type_from(t: Type) -> KirType {
  match (t) {
    Type.Int => KirType.Int
    Type.UInt => KirType.UInt
    Type.Float => KirType.Float
    Type.Bool => KirType.Bool
    Type.Char => KirType.Char
    Type.String => KirType.String
    Type.Array(inner) => KirType.Array(kir_type_from(inner))
    Type.Tuple(elems) => {
      let out = List.new();
      let i = 0; while (i < elems.len()) { out.push(kir_type_from(elems[i])); i = i + 1; }
      KirType.Tuple(out)
    }
    Type.Func(_, _) => KirType.Ptr(KirType.Int)
    _ => KirType.Int
  }
}

fun new_reg(ctx: LowerCtx) -> String {
  let name = "%" + ctx.next_reg.to_string();
  ctx.next_reg = ctx.next_reg + 1;
  name
}

fun bind(ctx: LowerCtx, name: String, reg: String, ty: KirType) {
  ctx.bindings.push(Binding { name: name, reg: reg, ty: ty });
}

fun lookup(ctx: LowerCtx, name: String) -> KirValue {
  let i = 0;
  while (i < ctx.bindings.len()) {
    if (ctx.bindings[i].name == name) {
      return KirValue.Reg(ctx.bindings[i].reg, ctx.bindings[i].ty);
    }
    i = i + 1;
  }
  KirValue.Reg("%undef", KirType.Int)
}

fun current_block(ctx: LowerCtx) -> KirBlock { ctx.blocks[ctx.current] }

fun push_instr(ctx: LowerCtx, instr: KirInstr) {
  let b = current_block(ctx);
  b.instrs.push(instr);
}

// helpers on KirValue
fun KirValue_ty(self: KirValue) -> KirType {
  match (self) {
    KirValue.Reg(_, t) => t
    KirValue.Const(_, t) => t
  }
}

fun KirValue_reg_name(self: KirValue) -> String {
  match (self) {
    KirValue.Reg(n, _) => n
    _ => "%const"
  }
}
// Self-hosted LLVM bindings and IR emission



// FFI declarations (placeholders for LLVM C API)
struct LLVMContext {
}
struct LLVMModule {
}
struct LLVMBuilder {
}
struct LLVMType {
}
struct LLVMValue {
}

fun llvm_init() -> Bool
fun llvm_create_context() -> LLVMContext
fun llvm_create_module(ctx: LLVMContext, name: String) -> LLVMModule
fun llvm_create_builder(ctx: LLVMContext) -> LLVMBuilder
fun llvm_i64_type(ctx: LLVMContext) -> LLVMType
fun llvm_f64_type(ctx: LLVMContext) -> LLVMType
fun llvm_void_type(ctx: LLVMContext) -> LLVMType
fun llvm_pointer_type(ty: LLVMType) -> LLVMType
fun llvm_function_type(ret: LLVMType, params: Any) -> LLVMType
fun llvm_add_function(module: LLVMModule, name: String, fnty: LLVMType) -> LLVMValue
fun llvm_build_ret(builder: LLVMBuilder, value: LLVMValue?) -> LLVMValue
fun llvm_build_call(builder: LLVMBuilder, fn: LLVMValue, args: Any) -> LLVMValue
fun llvm_write_bitcode(module: LLVMModule, path: String) -> Bool

// Real implementation for now: textual LLVM IR emission.

fun emit_llvm_ir(mod: KirModule) -> String

fun emit_llvm_ir(mod: KirModule) -> String {
  let out = " ";
  let i = 0;
  while (i < mod.functions.len()) {
    out = out + emit_fn(mod.functions[i]);
    i = i + 1;
  }
  out
}

fun emit_fn(f: KirFunction) -> String {
  let ret = emit_ty(f.ret);
  let params = " ";
  let i = 0;
  while (i < f.params.len()) {
    let p = f.params[i];
    let frag = emit_ty(p.ty) + " %" + p.name;
    params = params + (if (i == 0) { frag } else { ", " + frag });
    i = i + 1;
  }
  let body = " ";
  let b = 0;
  while (b < f.blocks.len()) {
    body = body + f.blocks[b].label + ":\n" + emit_block(f.blocks[b]);
    b = b + 1;
  }
  "define " + ret + " @" + f.name + "(" + params + ") \{\n" + body + "\}\n\n"
}

fun emit_block(b: KirBlock) -> String {
  let out = " ";
  let i = 0;
  while (i < b.instrs.len()) {
    out = out + "  " + emit_instr(b.instrs[i]) + "\n";
    i = i + 1;
  }
  out
}

fun emit_instr(i: KirInstr) -> String {
  match (i) {
    KirInstr.Return(v) => if (v != null) { "ret " + emit_ty(v.ty()) + " " + emit_val(v) } else { "ret void" }
    KirInstr.Let(name, ty, v) => name + " = add " + emit_ty(ty) + " " + emit_val(v) + ", 0"
    KirInstr.Assign(name, v) => name + " = add " + emit_ty(v.ty()) + " " + emit_val(v) + ", 0"
    KirInstr.Call(name, args) => {
      let params = " ";
      let j = 0;
      while (j < args.len()) {
        let frag = emit_ty(args[j].ty()) + " " + emit_val(args[j]);
        params = params + (if (j == 0) { frag } else { ", " + frag });
        j = j + 1;
      }
      "call void @" + name + "(" + params + ")"
    }
    KirInstr.Branch(label) => "br label %" + label
    KirInstr.CondBranch(v, t, f) => "br i1 " + emit_val(v) + ", label %" + t + ", label %" + f
    _ => " "
  }
}

fun emit_val(v: KirValue) -> String {
  match (v) {
    KirValue.Reg(n, _) => n
    KirValue.Const(lit, _) => match (lit) {
      Literal.Int(x) => x.to_string()
      Literal.Float(x) => x.to_string()
      Literal.Char(x) => x.to_string()
      Literal.Bool(x) => if (x) { "1" } else { "0" }
      Literal.String(_) => "null"
    }
  }
}

fun emit_ty(t: KirType) -> String {
  match (t) {
    KirType.Int => "i64"
    KirType.UInt => "i64"
    KirType.Float => "double"
    KirType.Bool => "i1"
    KirType.Char => "i32"
    KirType.String => "i8*"
    KirType.Array(inner) => emit_ty(inner) + "*"
    KirType.Tuple(_) => "i8*"
    KirType.Struct(_) => "i8*"
    KirType.Ptr(inner) => emit_ty(inner) + "*"
    KirType.Void => "void"
  }
}
// Self-hosted semantic analysis: @nogc validation and escape analysis



struct FuncInfo {
  name: String;
  nogc: Bool;
}

struct NogcCtx {
  funcs: Any;
  symtab: SymbolTable;
}

fun validate_nogc(prog: Program) -> Any

// internal
fun check_fun(ctx: NogcCtx, f: FunDecl, diags: Any)
fun check_stmt(ctx: NogcCtx, stmt: Stmt, diags: Any)
fun check_expr(ctx: NogcCtx, expr: Expr, diags: Any) -> Type
fun is_nogc_func(ctx: NogcCtx, name: String) -> Bool
fun is_alloc_type(t: Type) -> Bool

fun validate_nogc(prog: Program) -> Any {
  let diags = List.new();
  let funcs = List.new();
  let i = 0;
  while (i < prog.items.len()) {
    match (prog.items[i]) {
      Item.Fun(f) => funcs.push(FuncInfo { name: f.name, nogc: f.nogc })
      _ => {}
    }
    i = i + 1;
  }
  let ctx = NogcCtx { funcs: funcs, symtab: SymbolTable_new() };

  let j = 0;
  while (j < prog.items.len()) {
    match (prog.items[j]) {
      Item.Fun(f) => { if (f.nogc) { check_fun(ctx, f, diags); } }
      _ => {}
    }
    j = j + 1;
  }

  diags
}

fun check_fun(ctx: NogcCtx, f: FunDecl, diags: Any) {
  ctx.symtab.enter();
  let i = 0;
  while (i < f.params.len()) {
    let p = f.params[i];
    ctx.symtab.define(p.name, type_from_ref(p.ty), false, SymbolKind.Var);
    i = i + 1;
  }
  let body_ty = check_expr(ctx, Expr.Block(f.body), diags);
  if (f.ret != null) {
    let ret_ty = type_from_ref(f.ret);
    if (is_alloc_type(ret_ty)) {
      diags.push(Diagnostic_new("@nogc cannot return heap-allocated type", f.span));
    }
  } else {
    if (is_alloc_type(body_ty)) {
      diags.push(Diagnostic_new("@nogc cannot return heap-allocated type", f.span));
    }
  }
  ctx.symtab.exit();
}

fun check_stmt(ctx: NogcCtx, stmt: Stmt, diags: Any) {
  match (stmt) {
    Stmt.Var(v) => {
      let t = check_expr(ctx, v.value, diags);
      ctx.symtab.define(v.name, t, v.mutable, SymbolKind.Var);
    }
    Stmt.Expr(e, _) => { check_expr(ctx, e, diags); }
    Stmt.Return(e, span) => {
      if (e != null) {
        let t = check_expr(ctx, e, diags);
        if (is_alloc_type(t)) {
          diags.push(Diagnostic_new("@nogc return escapes heap allocation", span));
        }
      }
    }
    Stmt.If(cond, then_block, else_stmt, _) => {
      check_expr(ctx, cond, diags);
      check_stmt(ctx, Stmt.Block(then_block), diags);
      if (else_stmt != null) { check_stmt(ctx, else_stmt, diags); }
    }
    Stmt.While(cond, body, _) => { check_expr(ctx, cond, diags); check_stmt(ctx, Stmt.Block(body), diags); }
    Stmt.For(name, iter, body, _) => {
      check_expr(ctx, iter, diags);
      ctx.symtab.enter();
      ctx.symtab.define(name, Type.Unknown, false, SymbolKind.Var);
      check_stmt(ctx, Stmt.Block(body), diags);
      ctx.symtab.exit();
    }
    Stmt.Match(expr, arms, _) => {
      check_expr(ctx, expr, diags);
      let i = 0; while (i < arms.len()) { check_expr(ctx, arms[i].body, diags); i = i + 1; }
    }
    Stmt.Block(b) => {
      ctx.symtab.enter();
      let i = 0; while (i < b.stmts.len()) { check_stmt(ctx, b.stmts[i], diags); i = i + 1; }
      if (b.tail != null) { check_expr(ctx, b.tail, diags); }
      ctx.symtab.exit();
    }
    _ => {}
  }
}

fun check_expr(ctx: NogcCtx, expr: Expr, diags: Any) -> Type {
  match (expr) {
    Expr.Literal(l, span) => {
      match (l) {
        Literal.String(_) => diags.push(Diagnostic_new("allocation not allowed in @nogc", span))
        _ => {}
      }
      match (l) {
        Literal.Int(_) => Type.Int
        Literal.Float(_) => Type.Float
        Literal.String(_) => Type.String
        Literal.Char(_) => Type.Char
        Literal.Bool(_) => Type.Bool
      }
    }
    Expr.Ident(name, span) => {
      let sym = ctx.symtab.lookup(name);
      if (sym == null) { diags.push(Diagnostic_new("undefined symbol '" + name + "'", span)); return Type.Unknown; }
      sym.ty
    }
    Expr.Array(items, span) => {
      diags.push(Diagnostic_new("allocation not allowed in @nogc", span));
      let i = 0; while (i < items.len()) { check_expr(ctx, items[i], diags); i = i + 1; }
      Type.Array(Type.Any)
    }
    Expr.Tensor(_, span) => { diags.push(Diagnostic_new("allocation not allowed in @nogc", span)); Type.Tensor(Type.Float) }
    Expr.Interpolated(parts, span) => {
      diags.push(Diagnostic_new("allocation not allowed in @nogc", span));
      let i = 0; while (i < parts.len()) { check_expr(ctx, parts[i], diags); i = i + 1; }
      Type.String
    }
    Expr.Call(callee, args, span) => {
      match (callee) {
        Expr.Ident(name, _) => {
          if (!is_nogc_func(ctx, name)) {
            diags.push(Diagnostic_new("call to non-@nogc function in @nogc", span));
          }
        }
        _ => {}
      }
      let i = 0; while (i < args.len()) { check_expr(ctx, args[i], diags); i = i + 1; }
      Type.Unknown
    }
    Expr.Binary(l, _, r, _) => { check_expr(ctx, l, diags); check_expr(ctx, r, diags); Type.Unknown }
    Expr.Unary(_, e, _) => { check_expr(ctx, e, diags); Type.Unknown }
    Expr.Assign(l, _, r, _) => { check_expr(ctx, l, diags); check_expr(ctx, r, diags); Type.Unknown }
    Expr.Member(t, _, _) => { check_expr(ctx, t, diags); Type.Unknown }
    Expr.Index(t, i, _) => { check_expr(ctx, t, diags); check_expr(ctx, i, diags); Type.Unknown }
    Expr.If(c, t, e, _) => { check_expr(ctx, c, diags); check_expr(ctx, Expr.Block(t), diags); check_expr(ctx, Expr.Block(e), diags); Type.Unknown }
    Expr.Match(e, arms, _) => { check_expr(ctx, e, diags); let i = 0; while (i < arms.len()) { check_expr(ctx, arms[i].body, diags); i = i + 1; } Type.Unknown }
    Expr.Block(b) => { check_stmt(ctx, Stmt.Block(b), diags); Type.Unknown }
  }
}

fun is_nogc_func(ctx: NogcCtx, name: String) -> Bool {
  let i = 0;
  while (i < ctx.funcs.len()) {
    if (ctx.funcs[i].name == name) { return ctx.funcs[i].nogc; }
    i = i + 1;
  }
  false
}

fun is_alloc_type(t: Type) -> Bool {
  match (t) {
    Type.String => true
    Type.Array(_) => true
    Type.Tensor(_) => true
    _ => false
  }
}
// Phase 15.1: region-based lifetime inference (conservative)



struct VarRegion {
  name: String;
  region: Int;
  alloc_like: Bool;
}

struct RegionCtx {
  next_region: Int;
  root_region: Int;
  vars: Any;
}

fun region_infer_program(prog: Program) -> Any

fun region_check_item(ctx: RegionCtx, item: Item, diags: Any)
fun region_check_fun(ctx: RegionCtx, f: FunDecl, diags: Any)
fun region_check_block(ctx: RegionCtx, b: Block, region: Int, diags: Any)
fun region_check_stmt(ctx: RegionCtx, stmt: Stmt, region: Int, diags: Any)
fun region_check_expr(ctx: RegionCtx, expr: Expr, region: Int, diags: Any)

fun region_is_alloc_expr(expr: Expr) -> Bool
fun region_lookup_var_region(ctx: RegionCtx, name: String) -> VarRegion?
fun region_set_var_region(ctx: RegionCtx, name: String, region: Int, alloc_like: Bool)

fun region_infer_program(prog: Program) -> Any {
  let diags = List.new();
  let ctx = RegionCtx { next_region: 1, root_region: 0, vars: List.new() };

  let i = 0;
  while (i < prog.items.len()) {
    region_check_item(ctx, prog.items[i], diags);
    i = i + 1;
  }
  diags
}

fun region_check_item(ctx: RegionCtx, item: Item, diags: Any) {
  match (item) {
    Item.Fun(f) => region_check_fun(ctx, f, diags)
    Item.Const(v) => {
      let alloc_like = region_is_alloc_expr(v.value);
      region_set_var_region(ctx, v.name, 0, alloc_like);
      region_check_expr(ctx, v.value, 0, diags);
    }
    Item.Stmt(s) => region_check_stmt(ctx, s, 0, diags)
    _ => {}
  }
}

fun region_check_fun(ctx: RegionCtx, f: FunDecl, diags: Any) {
  let saved = ctx.vars;
  let root = ctx.next_region;
  ctx.next_region = ctx.next_region + 1;
  ctx.root_region = root;

  let i = 0;
  while (i < f.params.len()) {
    region_set_var_region(ctx, f.params[i].name, root, false);
    i = i + 1;
  }

  region_check_block(ctx, f.body, root, diags);

  ctx.vars = saved;
}

fun region_check_block(ctx: RegionCtx, b: Block, region: Int, diags: Any) {
  let i = 0;
  while (i < b.stmts.len()) {
    region_check_stmt(ctx, b.stmts[i], region, diags);
    i = i + 1;
  }
  if (b.tail != null) {
    region_check_expr(ctx, b.tail, region, diags);
  }
}

fun region_check_stmt(ctx: RegionCtx, stmt: Stmt, region: Int, diags: Any) {
  match (stmt) {
    Stmt.Var(v) => {
      let alloc_like = region_is_alloc_expr(v.value);
      region_set_var_region(ctx, v.name, region, alloc_like);
      region_check_expr(ctx, v.value, region, diags);
    }
    Stmt.Return(e, span) => {
      if (e != null) {
        region_check_expr(ctx, e, region, diags);
        match (e) {
          Expr.Ident(name, _) => {
            let vr = region_lookup_var_region(ctx, name);
            if (vr != null && vr.alloc_like && vr.region != ctx.root_region) {
              diags.push(Diagnostic_new("region escape: local allocation returned from narrower scope", span));
            }
          }
          _ => {}
        }
      }
    }
    Stmt.If(cond, then_block, else_stmt, _) => {
      region_check_expr(ctx, cond, region, diags);
      let r1 = ctx.next_region;
      ctx.next_region = ctx.next_region + 1;
      region_check_block(ctx, then_block, r1, diags);
      if (else_stmt != null) {
        match (else_stmt) {
          Stmt.Block(b) => {
            let r2 = ctx.next_region;
            ctx.next_region = ctx.next_region + 1;
            region_check_block(ctx, b, r2, diags);
          }
          _ => region_check_stmt(ctx, else_stmt, region, diags)
        }
      }
    }
    Stmt.While(cond, body, _) => {
      region_check_expr(ctx, cond, region, diags);
      let r = ctx.next_region;
      ctx.next_region = ctx.next_region + 1;
      region_check_block(ctx, body, r, diags);
    }
    Stmt.For(name, iter, body, _) => {
      region_check_expr(ctx, iter, region, diags);
      let r = ctx.next_region;
      ctx.next_region = ctx.next_region + 1;
      region_set_var_region(ctx, name, r, false);
      region_check_block(ctx, body, r, diags);
    }
    Stmt.Match(e, arms, _) => {
      region_check_expr(ctx, e, region, diags);
      let i = 0;
      while (i < arms.len()) {
        region_check_expr(ctx, arms[i].body, region, diags);
        i = i + 1;
      }
    }
    Stmt.Block(b) => {
      let r = ctx.next_region;
      ctx.next_region = ctx.next_region + 1;
      region_check_block(ctx, b, r, diags);
    }
    Stmt.Expr(e, _) => region_check_expr(ctx, e, region, diags)
    _ => {}
  }
}

fun region_check_expr(ctx: RegionCtx, expr: Expr, region: Int, diags: Any) {
  match (expr) {
    Expr.Unary(_, e, _) => region_check_expr(ctx, e, region, diags)
    Expr.Binary(l, _, r, _) => { region_check_expr(ctx, l, region, diags); region_check_expr(ctx, r, region, diags); }
    Expr.Assign(l, _, r, _) => { region_check_expr(ctx, l, region, diags); region_check_expr(ctx, r, region, diags); }
    Expr.Call(c, args, _) => {
      region_check_expr(ctx, c, region, diags);
      let i = 0;
      while (i < args.len()) { region_check_expr(ctx, args[i], region, diags); i = i + 1; }
    }
    Expr.Member(t, _, _) => region_check_expr(ctx, t, region, diags)
    Expr.Index(t, i, _) => { region_check_expr(ctx, t, region, diags); region_check_expr(ctx, i, region, diags); }
    Expr.If(c, tb, eb, _) => {
      region_check_expr(ctx, c, region, diags);
      region_check_block(ctx, tb, region, diags);
      region_check_block(ctx, eb, region, diags);
    }
    Expr.Match(e, arms, _) => {
      region_check_expr(ctx, e, region, diags);
      let i = 0;
      while (i < arms.len()) { region_check_expr(ctx, arms[i].body, region, diags); i = i + 1; }
    }
    Expr.Block(b) => region_check_block(ctx, b, region, diags)
    Expr.Array(items, _) => {
      let i = 0;
      while (i < items.len()) { region_check_expr(ctx, items[i], region, diags); i = i + 1; }
    }
    Expr.Tensor(rows, _) => {
      let r = 0;
      while (r < rows.len()) {
        let c = 0;
        while (c < rows[r].len()) { region_check_expr(ctx, rows[r][c], region, diags); c = c + 1; }
        r = r + 1;
      }
    }
    Expr.Interpolated(parts, _) => {
      let i = 0;
      while (i < parts.len()) { region_check_expr(ctx, parts[i], region, diags); i = i + 1; }
    }
    _ => {}
  }
}

fun region_is_alloc_expr(expr: Expr) -> Bool {
  match (expr) {
    Expr.Array(_, _) => true
    Expr.Tensor(_, _) => true
    Expr.Interpolated(_, _) => true
    Expr.Literal(l, _) => match (l) { Literal.String(_) => true _ => false }
    Expr.Call(callee, _, _) => {
      match (callee) {
        Expr.Ident(name, _) => name == "alloc" || name == "unique_new" || name == "shared_new"
        _ => false
      }
    }
    _ => false
  }
}

fun region_lookup_var_region(ctx: RegionCtx, name: String) -> VarRegion? {
  let i = 0;
  while (i < ctx.vars.len()) {
    if (ctx.vars[i].name == name) { return ctx.vars[i]; }
    i = i + 1;
  }
  null
}

fun region_set_var_region(ctx: RegionCtx, name: String, region: Int, alloc_like: Bool) {
  let i = 0;
  while (i < ctx.vars.len()) {
    if (ctx.vars[i].name == name) {
      ctx.vars[i].region = region;
      ctx.vars[i].alloc_like = alloc_like;
      return;
    }
    i = i + 1;
  }
  ctx.vars.push(VarRegion { name: name, region: region, alloc_like: alloc_like });
}
// Phase 15.2: linear/move semantic checks (conservative)



struct BindState {
  name: String;
  unique_like: Bool;
  moved: Bool;
}

struct LinearCtx {
  binds: Any;
}

fun linear_check_program(prog: Program) -> Any

fun linear_check_item(ctx: LinearCtx, item: Item, diags: Any)
fun linear_check_fun(ctx: LinearCtx, f: FunDecl, diags: Any)
fun linear_check_stmt(ctx: LinearCtx, stmt: Stmt, diags: Any)
fun linear_check_expr(ctx: LinearCtx, expr: Expr, diags: Any, in_move_arg: Bool)

fun linear_add_bind(ctx: LinearCtx, name: String, unique_like: Bool)
fun linear_lookup_bind(ctx: LinearCtx, name: String) -> BindState?
fun linear_mark_moved(ctx: LinearCtx, name: String)
fun linear_is_unique_decl(v: VarDecl) -> Bool

fun linear_check_program(prog: Program) -> Any {
  let diags = List.new();
  let ctx = LinearCtx { binds: List.new() };

  let i = 0;
  while (i < prog.items.len()) {
    linear_check_item(ctx, prog.items[i], diags);
    i = i + 1;
  }
  diags
}

fun linear_check_item(ctx: LinearCtx, item: Item, diags: Any) {
  match (item) {
    Item.Fun(f) => linear_check_fun(ctx, f, diags)
    Item.Const(v) => {
      linear_add_bind(ctx, v.name, linear_is_unique_decl(v));
      linear_check_expr(ctx, v.value, diags, false);
    }
    Item.Stmt(s) => linear_check_stmt(ctx, s, diags)
    _ => {}
  }
}

fun linear_check_fun(ctx: LinearCtx, f: FunDecl, diags: Any) {
  let saved = ctx.binds;
  ctx.binds = List.new();

  let i = 0;
  while (i < f.params.len()) {
    let is_unique = match (f.params[i].ty) {
      TypeRef.Named(name, _) => name == "Unique"
      _ => false
    };
    linear_add_bind(ctx, f.params[i].name, is_unique);
    i = i + 1;
  }

  let j = 0;
  while (j < f.body.stmts.len()) {
    linear_check_stmt(ctx, f.body.stmts[j], diags);
    j = j + 1;
  }
  if (f.body.tail != null) {
    linear_check_expr(ctx, f.body.tail, diags, false);
  }

  ctx.binds = saved;
}

fun linear_check_stmt(ctx: LinearCtx, stmt: Stmt, diags: Any) {
  match (stmt) {
    Stmt.Var(v) => {
      linear_add_bind(ctx, v.name, linear_is_unique_decl(v));
      linear_check_expr(ctx, v.value, diags, false);
    }
    Stmt.Expr(e, _) => linear_check_expr(ctx, e, diags, false)
    Stmt.Return(e, _) => { if (e != null) { linear_check_expr(ctx, e, diags, false); } }
    Stmt.If(c, tb, es, _) => {
      linear_check_expr(ctx, c, diags, false);
      let i = 0;
      while (i < tb.stmts.len()) { linear_check_stmt(ctx, tb.stmts[i], diags); i = i + 1; }
      if (tb.tail != null) { linear_check_expr(ctx, tb.tail, diags, false); }
      if (es != null) { linear_check_stmt(ctx, es, diags); }
    }
    Stmt.While(c, b, _) => {
      linear_check_expr(ctx, c, diags, false);
      let i = 0;
      while (i < b.stmts.len()) { linear_check_stmt(ctx, b.stmts[i], diags); i = i + 1; }
      if (b.tail != null) { linear_check_expr(ctx, b.tail, diags, false); }
    }
    Stmt.For(name, iter, b, _) => {
      linear_add_bind(ctx, name, false);
      linear_check_expr(ctx, iter, diags, false);
      let i = 0;
      while (i < b.stmts.len()) { linear_check_stmt(ctx, b.stmts[i], diags); i = i + 1; }
      if (b.tail != null) { linear_check_expr(ctx, b.tail, diags, false); }
    }
    Stmt.Match(e, arms, _) => {
      linear_check_expr(ctx, e, diags, false);
      let i = 0;
      while (i < arms.len()) { linear_check_expr(ctx, arms[i].body, diags, false); i = i + 1; }
    }
    Stmt.Block(b) => {
      let i = 0;
      while (i < b.stmts.len()) { linear_check_stmt(ctx, b.stmts[i], diags); i = i + 1; }
      if (b.tail != null) { linear_check_expr(ctx, b.tail, diags, false); }
    }
    _ => {}
  }
}

fun linear_check_expr(ctx: LinearCtx, expr: Expr, diags: Any, in_move_arg: Bool) {
  match (expr) {
    Expr.Ident(name, span) => {
      let b = linear_lookup_bind(ctx, name);
      if (b != null && b.unique_like && b.moved && !in_move_arg) {
        diags.push(Diagnostic_new("use after move: '" + name + "'", span));
      }
    }
    Expr.Call(callee, args, span) => {
      let is_move = false;
      match (callee) {
        Expr.Ident(name, _) => { if (name == "move") { is_move = true; } }
        _ => {}
      }

      linear_check_expr(ctx, callee, diags, false);

      let i = 0;
      while (i < args.len()) {
        let a = args[i];
        linear_check_expr(ctx, a, diags, is_move);

        if (is_move) {
          match (a) {
            Expr.Ident(name, _) => linear_mark_moved(ctx, name)
            _ => diags.push(Diagnostic_new("move() expects an identifier", span))
          }
        } else {
          match (a) {
            Expr.Ident(name, arg_span) => {
              let b = linear_lookup_bind(ctx, name);
              if (b != null && b.unique_like && !b.moved) {
                diags.push(Diagnostic_new("copy of Unique value requires move()", arg_span));
              }
            }
            _ => {}
          }
        }
        i = i + 1;
      }
    }
    Expr.Assign(l, _, r, span) => {
      linear_check_expr(ctx, l, diags, false);
      linear_check_expr(ctx, r, diags, false);
      match (r) {
        Expr.Ident(name, _) => {
          let b = linear_lookup_bind(ctx, name);
          if (b != null && b.unique_like && !b.moved) {
            diags.push(Diagnostic_new("assignment from Unique requires move()", span));
          }
        }
        _ => {}
      }
    }
    Expr.Unary(_, e, _) => linear_check_expr(ctx, e, diags, false)
    Expr.Binary(l, _, r, _) => { linear_check_expr(ctx, l, diags, false); linear_check_expr(ctx, r, diags, false); }
    Expr.Member(t, _, _) => linear_check_expr(ctx, t, diags, false)
    Expr.Index(t, i, _) => { linear_check_expr(ctx, t, diags, false); linear_check_expr(ctx, i, diags, false); }
    Expr.If(c, tb, eb, _) => {
      linear_check_expr(ctx, c, diags, false);
      let i = 0; while (i < tb.stmts.len()) { linear_check_stmt(ctx, tb.stmts[i], diags); i = i + 1; }
      if (tb.tail != null) { linear_check_expr(ctx, tb.tail, diags, false); }
      let j = 0; while (j < eb.stmts.len()) { linear_check_stmt(ctx, eb.stmts[j], diags); j = j + 1; }
      if (eb.tail != null) { linear_check_expr(ctx, eb.tail, diags, false); }
    }
    Expr.Match(e, arms, _) => {
      linear_check_expr(ctx, e, diags, false);
      let i = 0; while (i < arms.len()) { linear_check_expr(ctx, arms[i].body, diags, false); i = i + 1; }
    }
    Expr.Block(b) => {
      let i = 0; while (i < b.stmts.len()) { linear_check_stmt(ctx, b.stmts[i], diags); i = i + 1; }
      if (b.tail != null) { linear_check_expr(ctx, b.tail, diags, false); }
    }
    Expr.Array(items, _) => {
      let i = 0; while (i < items.len()) { linear_check_expr(ctx, items[i], diags, false); i = i + 1; }
    }
    Expr.Tensor(rows, _) => {
      let r = 0;
      while (r < rows.len()) {
        let c = 0;
        while (c < rows[r].len()) { linear_check_expr(ctx, rows[r][c], diags, false); c = c + 1; }
        r = r + 1;
      }
    }
    Expr.Interpolated(parts, _) => {
      let i = 0; while (i < parts.len()) { linear_check_expr(ctx, parts[i], diags, false); i = i + 1; }
    }
    _ => {}
  }
}

fun linear_add_bind(ctx: LinearCtx, name: String, unique_like: Bool) {
  let i = 0;
  while (i < ctx.binds.len()) {
    if (ctx.binds[i].name == name) {
      ctx.binds[i].unique_like = unique_like;
      ctx.binds[i].moved = false;
      return;
    }
    i = i + 1;
  }
  ctx.binds.push(BindState { name: name, unique_like: unique_like, moved: false });
}

fun linear_lookup_bind(ctx: LinearCtx, name: String) -> BindState? {
  let i = 0;
  while (i < ctx.binds.len()) {
    if (ctx.binds[i].name == name) { return ctx.binds[i]; }
    i = i + 1;
  }
  null
}

fun linear_mark_moved(ctx: LinearCtx, name: String) {
  let i = 0;
  while (i < ctx.binds.len()) {
    if (ctx.binds[i].name == name) {
      if (ctx.binds[i].unique_like) {
        ctx.binds[i].moved = true;
      }
      return;
    }
    i = i + 1;
  }
}

fun linear_is_unique_decl(v: VarDecl) -> Bool {
  if (v.ty != null) {
    match (v.ty) {
      TypeRef.Named(name, _) => { if (name == "Unique") { return true; } }
      _ => {}
    }
  }

  match (v.value) {
    Expr.Call(callee, _, _) => {
      match (callee) {
        Expr.Ident(name, _) => name == "unique_new" || name == "unique_from_raw"
        _ => false
      }
    }
    _ => false
  }
}
// Phase 15.3: zero-cost smart pointer semantics (compile-time only)



struct PtrBinding {
  name: String;
  ptr_kind: String; // "Unique" | "Shared"
}

struct PtrCtx {
  binds: Any;
}

fun smartptr_validate_program(prog: Program) -> Any

fun smartptr_check_item(ctx: PtrCtx, item: Item, diags: Any)
fun smartptr_check_stmt(ctx: PtrCtx, stmt: Stmt, diags: Any)
fun smartptr_check_expr(ctx: PtrCtx, expr: Expr, diags: Any)

fun smartptr_decl_ptr_kind(v: VarDecl) -> String?
fun smartptr_infer_ctor_kind(ctx: PtrCtx, expr: Expr) -> String?
fun smartptr_add_ptr_bind(ctx: PtrCtx, name: String, kind: String)
fun smartptr_lookup_ptr_bind(ctx: PtrCtx, name: String) -> String?

fun smartptr_validate_program(prog: Program) -> Any {
  let diags = List.new();
  let ctx = PtrCtx { binds: List.new() };

  let i = 0;
  while (i < prog.items.len()) {
    smartptr_check_item(ctx, prog.items[i], diags);
    i = i + 1;
  }
  diags
}

fun smartptr_check_item(ctx: PtrCtx, item: Item, diags: Any) {
  match (item) {
    Item.Fun(f) => {
      let saved = ctx.binds;
      ctx.binds = List.new();
      let i = 0;
      while (i < f.body.stmts.len()) { smartptr_check_stmt(ctx, f.body.stmts[i], diags); i = i + 1; }
      if (f.body.tail != null) { smartptr_check_expr(ctx, f.body.tail, diags); }
      ctx.binds = saved;
    }
    Item.Const(v) => {
      let dk = smartptr_decl_ptr_kind(v);
      let ck = smartptr_infer_ctor_kind(ctx, v.value);
      if (dk != null) {
        if (ck != null && dk != ck) {
          diags.push(Diagnostic_new("smart pointer kind mismatch in declaration", v.span));
        }
        smartptr_add_ptr_bind(ctx, v.name, dk);
      }
      smartptr_check_expr(ctx, v.value, diags);
    }
    Item.Stmt(s) => smartptr_check_stmt(ctx, s, diags)
    _ => {}
  }
}

fun smartptr_check_stmt(ctx: PtrCtx, stmt: Stmt, diags: Any) {
  match (stmt) {
    Stmt.Var(v) => {
      let dk = smartptr_decl_ptr_kind(v);
      let ck = smartptr_infer_ctor_kind(ctx, v.value);
      if (dk != null) {
        if (ck != null && dk != ck) {
          diags.push(Diagnostic_new("smart pointer kind mismatch in declaration", v.span));
        }
        smartptr_add_ptr_bind(ctx, v.name, dk);
      }
      smartptr_check_expr(ctx, v.value, diags);
    }
    Stmt.Expr(e, _) => smartptr_check_expr(ctx, e, diags)
    Stmt.Return(e, _) => { if (e != null) { smartptr_check_expr(ctx, e, diags); } }
    Stmt.If(c, tb, es, _) => {
      smartptr_check_expr(ctx, c, diags);
      let i = 0; while (i < tb.stmts.len()) { smartptr_check_stmt(ctx, tb.stmts[i], diags); i = i + 1; }
      if (tb.tail != null) { smartptr_check_expr(ctx, tb.tail, diags); }
      if (es != null) { smartptr_check_stmt(ctx, es, diags); }
    }
    Stmt.While(c, b, _) => {
      smartptr_check_expr(ctx, c, diags);
      let i = 0; while (i < b.stmts.len()) { smartptr_check_stmt(ctx, b.stmts[i], diags); i = i + 1; }
      if (b.tail != null) { smartptr_check_expr(ctx, b.tail, diags); }
    }
    Stmt.For(_, iter, b, _) => {
      smartptr_check_expr(ctx, iter, diags);
      let i = 0; while (i < b.stmts.len()) { smartptr_check_stmt(ctx, b.stmts[i], diags); i = i + 1; }
      if (b.tail != null) { smartptr_check_expr(ctx, b.tail, diags); }
    }
    Stmt.Match(e, arms, _) => {
      smartptr_check_expr(ctx, e, diags);
      let i = 0; while (i < arms.len()) { smartptr_check_expr(ctx, arms[i].body, diags); i = i + 1; }
    }
    Stmt.Block(b) => {
      let i = 0; while (i < b.stmts.len()) { smartptr_check_stmt(ctx, b.stmts[i], diags); i = i + 1; }
      if (b.tail != null) { smartptr_check_expr(ctx, b.tail, diags); }
    }
    _ => {}
  }
}

fun smartptr_check_expr(ctx: PtrCtx, expr: Expr, diags: Any) {
  match (expr) {
    Expr.Assign(left, _, right, span) => {
      smartptr_check_expr(ctx, left, diags);
      smartptr_check_expr(ctx, right, diags);
      match (left) {
        Expr.Ident(lname, _) => {
          let lk = smartptr_lookup_ptr_bind(ctx, lname);
          if (lk != null) {
            let rk = smartptr_infer_ctor_kind(ctx, right);
            if (rk != null && rk != lk) {
              diags.push(Diagnostic_new("smart pointer assignment kind mismatch", span));
            }
          }
        }
        _ => {}
      }
    }
    Expr.Call(callee, args, span) => {
      match (callee) {
        Expr.Ident(name, _) => {
          if (name == "unique_from_raw" || name == "shared_from_raw") {
            if (args.len() != 1) {
              diags.push(Diagnostic_new("*_from_raw expects one pointer argument", span));
            }
          }
          if (name == "unique_into_raw" && args.len() != 1) {
            diags.push(Diagnostic_new("unique_into_raw expects one argument", span));
          }
          if (name == "shared_clone" && args.len() != 1) {
            diags.push(Diagnostic_new("shared_clone expects one argument", span));
          }
        }
        _ => {}
      }

      smartptr_check_expr(ctx, callee, diags);
      let i = 0;
      while (i < args.len()) { smartptr_check_expr(ctx, args[i], diags); i = i + 1; }
    }
    Expr.Unary(_, e, _) => smartptr_check_expr(ctx, e, diags)
    Expr.Binary(l, _, r, _) => { smartptr_check_expr(ctx, l, diags); smartptr_check_expr(ctx, r, diags); }
    Expr.Member(t, _, _) => smartptr_check_expr(ctx, t, diags)
    Expr.Index(t, i, _) => { smartptr_check_expr(ctx, t, diags); smartptr_check_expr(ctx, i, diags); }
    Expr.If(c, tb, eb, _) => {
      smartptr_check_expr(ctx, c, diags);
      let i = 0; while (i < tb.stmts.len()) { smartptr_check_stmt(ctx, tb.stmts[i], diags); i = i + 1; }
      if (tb.tail != null) { smartptr_check_expr(ctx, tb.tail, diags); }
      let j = 0; while (j < eb.stmts.len()) { smartptr_check_stmt(ctx, eb.stmts[j], diags); j = j + 1; }
      if (eb.tail != null) { smartptr_check_expr(ctx, eb.tail, diags); }
    }
    Expr.Match(e, arms, _) => {
      smartptr_check_expr(ctx, e, diags);
      let i = 0; while (i < arms.len()) { smartptr_check_expr(ctx, arms[i].body, diags); i = i + 1; }
    }
    Expr.Block(b) => {
      let i = 0; while (i < b.stmts.len()) { smartptr_check_stmt(ctx, b.stmts[i], diags); i = i + 1; }
      if (b.tail != null) { smartptr_check_expr(ctx, b.tail, diags); }
    }
    Expr.Array(items, _) => {
      let i = 0; while (i < items.len()) { smartptr_check_expr(ctx, items[i], diags); i = i + 1; }
    }
    Expr.Tensor(rows, _) => {
      let r = 0;
      while (r < rows.len()) {
        let c = 0;
        while (c < rows[r].len()) { smartptr_check_expr(ctx, rows[r][c], diags); c = c + 1; }
        r = r + 1;
      }
    }
    Expr.Interpolated(parts, _) => {
      let i = 0; while (i < parts.len()) { smartptr_check_expr(ctx, parts[i], diags); i = i + 1; }
    }
    _ => {}
  }
}

fun smartptr_decl_ptr_kind(v: VarDecl) -> String? {
  if (v.ty == null) { return null; }
  match (v.ty) {
    TypeRef.Named(name, _) => {
      if (name == "Unique") { return "Unique"; }
      if (name == "Shared") { return "Shared"; }
      null
    }
    _ => null
  }
}

fun smartptr_infer_ctor_kind(ctx: PtrCtx, expr: Expr) -> String? {
  match (expr) {
    Expr.Call(callee, _, _) => {
      match (callee) {
        Expr.Ident(name, _) => {
          if (name == "unique_new" || name == "unique_from_raw" || name == "unique_into_raw") { return "Unique"; }
          if (name == "shared_new" || name == "shared_from_raw" || name == "shared_clone") { return "Shared"; }
          null
        }
        _ => null
      }
    }
    Expr.Ident(name, _) => smartptr_lookup_ptr_bind(ctx, name)
    _ => null
  }
}

fun smartptr_add_ptr_bind(ctx: PtrCtx, name: String, kind: String) {
  let i = 0;
  while (i < ctx.binds.len()) {
    if (ctx.binds[i].name == name) {
      ctx.binds[i].ptr_kind = kind;
      return;
    }
    i = i + 1;
  }
  ctx.binds.push(PtrBinding { name: name, ptr_kind: kind });
}

fun smartptr_lookup_ptr_bind(ctx: PtrCtx, name: String) -> String? {
  let i = 0;
  while (i < ctx.binds.len()) {
    if (ctx.binds[i].name == name) { return ctx.binds[i].ptr_kind; }
    i = i + 1;
  }
  null
}



struct HardeningState {
    diags: Any;
    symtab: SymbolTable;
    reachable: Bool;
}

fun HardeningState_new(symtab: SymbolTable) -> HardeningState {
    HardeningState {
        diags: List.new(),
        symtab: symtab,
        reachable: true
    }
}


fun check_visibility(state: HardeningState, sym: Symbol, span: Span) {
    if (sym.visibility == Visibility.Private) {
        
        
        
    }
}


fun check_dead_code(state: HardeningState, stmt: Stmt) {
    if (!state.reachable) {
        
    }
    
    match (stmt) {
        Stmt.Return(_, _) => { state.reachable = false; }
        Stmt.Break(_) => { state.reachable = false; }
        Stmt.Continue(_) => { state.reachable = false; }
        _ => {}
    }
}


fun fold_constant(expr: Expr) -> Expr {
    match (expr) {
        Expr.Binary(lhs, op, rhs, span) => {
            let l = fold_constant(lhs);
            let r = fold_constant(rhs);
            match (l) {
                Expr.Literal(Literal.Int(lv), _) => {
                    match (r) {
                        Expr.Literal(Literal.Int(rv), _) => {
                            if (op == BinaryOp.Add) { return Expr.Literal(Literal.Int(lv + rv), span); }
                            if (op == BinaryOp.Sub) { return Expr.Literal(Literal.Int(lv - rv), span); }
                            if (op == BinaryOp.Mul) { return Expr.Literal(Literal.Int(lv * rv), span); }
                        }
                        _ => {}
                    }
                }
                _ => {}
            }
            return Expr.Binary(l, op, r, span);
        }
        _ => expr
    }
}



fun mangle_name(module_name: String, symbol_name: String) -> String {
    module_name.replace(".", "_") + "__" + symbol_name
}


fun check_interface_fulfillment(state: HardeningState, class_name: String, interface_name: String) -> Bool {
    
    echo("Checking if " + class_name + " fulfills " + interface_name + "");
    true
}


fun check_exhaustive_match(state: HardeningState, enum_type: Type, arms: Any) {
    
    echo("Checking exhaustive match for enum");
}


fun resolve_operator_overload(state: HardeningState, op: BinaryOp, left: Type, right: Type) -> Type {
    
    left
}


fun check_lifetime(state: HardeningState, expr: Expr) {
    
}


fun analyze_escape(state: HardeningState, decl: VarDecl) -> Bool {
    
    false
}

fun check_uninitialized(state: HardeningState, name: String, span: Span) {
    let sym = state.symtab.lookup(name);
    if (sym == null) {
        state.diags.push(Diagnostic_new("Undefined variable: " + name, span));
    }
}

fun harden_program(prog: Program) -> Any {
    let symtab = SymbolTable_new();
    let state = HardeningState_new(symtab);
    
    let i = 0;
    while (i < prog.items.len()) {
        let item = prog.items[i];
        match (item) {
            Item.Fun(decl, _, vis) => {
                symtab.define(decl.name, Type.Func(List.new(), Type.Unit), false, SymbolKind.Func, vis);
            }
            Item.Struct(decl, _, vis) => {
                symtab.define(decl.name, Type.Named(decl.name, List.new(), decl.span), false, SymbolKind.Struct, vis);
            }
            _ => {}
        }
        i = i + 1;
    }
    
    state.diags
}
// Self-hosted semantic analysis entry point



struct Sema {
  diags: Any;
}

fun Sema_new() -> Sema
fun Sema_check_program(self: Sema, prog: Program) -> Any

fun Sema_new() -> Sema {
  Sema { diags: List.new() }
}

fun Sema_check_program(self: Sema, prog: Program) -> Any {
  let inferred = infer_program(prog);
  if (inferred.is_err()) {
    return Result.err(inferred.err());
  }

  let all_diags = List.new();

  let hardening_diags = harden_program(inferred.ok());
  let h = 0;
  while (h < hardening_diags.len()) { all_diags.push(hardening_diags[h]); h = h + 1; }

  let nogc_diags = validate_nogc(inferred.ok());
  let i = 0;
  while (i < nogc_diags.len()) { all_diags.push(nogc_diags[i]); i = i + 1; }

  let region_diags = region_infer_program(inferred.ok());
  let j = 0;
  while (j < region_diags.len()) { all_diags.push(region_diags[j]); j = j + 1; }

  let linear_diags = linear_check_program(inferred.ok());
  let k = 0;
  while (k < linear_diags.len()) { all_diags.push(linear_diags[k]); k = k + 1; }

  let ptr_diags = smartptr_validate_program(inferred.ok());
  let m = 0;
  while (m < ptr_diags.len()) { all_diags.push(ptr_diags[m]); m = m + 1; }

  if (all_diags.len() > 0) {
    return Result.err(all_diags);
  }

  Result.ok(inferred.ok())
}





let R_X86_64_NONE: UInt = 0;
let R_X86_64_64: UInt = 1;
let R_X86_64_PC32: UInt = 2;
let R_X86_64_PLT32: UInt = 4;
let R_X86_64_COPY: UInt = 5;
let R_X86_64_GLOB_DAT: UInt = 6;
let R_X86_64_JUMP_SLOT: UInt = 7;
let R_X86_64_RELATIVE: UInt = 8;

struct Relocation {
    offset: UInt;
    symbol_index: UInt;
    typ: UInt;
    addend: Int;
}


fun write_relocation_entry(buf: Any, reloc: Relocation) {
    
    linker.elf.push_u64(buf, reloc.offset);
    
    
    let info_lo = reloc.typ;
    let info_hi = reloc.symbol_index; 
    linker.elf.push_u32(buf, info_lo);
    linker.elf.push_u32(buf, info_hi);
    
    
    
    let addend_u = reloc.addend as UInt; 
    linker.elf.push_u64(buf, addend_u);
}

fun create_plt_reloc(offset: UInt, sym_idx: UInt) -> Relocation {
    Relocation {
        offset: offset,
        symbol_index: sym_idx,
        typ: R_X86_64_PLT32,
        addend: -4 
    }
}
// Native linker: ELF writer (subset)


struct ElfSection {
  name: String;
  data: Any;
  align: UInt;
}

struct ElfFile {
  sections: Any;
}

fun ElfFile_new() -> ElfFile {
  ElfFile { sections: List.new() }
}

fun elf_add_section(file: ElfFile, name: String, data: Any, align: UInt) {
  file.sections.push(ElfSection { name: name, data: data, align: align });
}

fun elf_write(_file: ElfFile) -> Any {
  // Placeholder bytes (real ELF requires headers + section tables)
  let out = List.new();
  out.push(0x7F);
  out.push(0x45); // 'E'
  out.push(0x4C); // 'L'
  out.push(0x46); // 'F'
  out
}




struct ObjectFile {
    name: String;
    sections: Any;
    relocs: Any;
    symbols: Any;
}

struct LinkerContext {
    objects: Any;
    output_path: String;
    entry_point: String;
}

fun LinkerContext_new(out: String) -> LinkerContext {
    LinkerContext {
        objects: List.new(),
        output_path: out,
        entry_point: "_start"
    }
}


fun linker_add_object(ctx: LinkerContext, obj: ObjectFile) {
    ctx.objects.push(obj);
}

fun linker_merge_sections(ctx: LinkerContext) -> Any {
    
    let merged_text = linker.elf.ElfSection { name: ".text", data: List.new(), align: 16 };
    let merged_data = linker.elf.ElfSection { name: ".data", data: List.new(), align: 16 };
    
    let i = 0;
    while (i < ctx.objects.len()) {
        let obj = ctx.objects[i];
        let j = 0;
        while (j < obj.sections.len()) {
            let sec = obj.sections[j];
            if (sec.name == ".text") {
                let k = 0;
                while (k < sec.data.len()) { merged_text.data.push(sec.data[k]); k = k + 1; }
            } else if (sec.name == ".data") {
                let k = 0;
                while (k < sec.data.len()) { merged_data.data.push(sec.data[k]); k = k + 1; }
            }
            j = j + 1;
        }
        i = i + 1;
    }
    
    let out = List.new();
    out.push(merged_text);
    out.push(merged_data);
    out
}

fun linker_emit_executable(ctx: LinkerContext) {
    let sections = linker_merge_sections(ctx);
    
    
    let ph_off = 64; 
    let ph_num = sections.len() as UInt; 
    let entry = 0x400000; 
    
    let hdr = linker.elf.ElfHeader {
        typ: linker.elf.ET_EXEC,
        machine: linker.elf.EM_X86_64,
        entry: entry,
        ph_off: ph_off,
        sh_off: 0, 
        ph_num: ph_num,
        sh_num: 0,
        sh_str_ndx: 0
    };
    
    let buf = List.new();
    linker.elf.write_elf_header(buf, hdr);
    
    
    let i = 0;
    let offset = ph_off + (ph_num * 56);
    while (i < sections.len()) {
        let sec = sections[i];
        let size = sec.data.len() as UInt;
        let flags = if (sec.name == ".text") { 5 } else { 6 }; 
        
        let ph = linker.elf.ProgramHeader {
            typ: linker.elf.PT_LOAD,
            flags: flags as UInt,
            offset: offset,
            vaddr: entry + offset,
            paddr: entry + offset,
            filesz: size,
            memsz: size,
            align: 0x1000
        };
        
        linker.elf.write_program_header(buf, ph);
        offset = offset + size;
        i = i + 1;
    }
    
    
    i = 0;
    while (i < sections.len()) {
        let sec = sections[i];
        let j = 0;
        while (j < sec.data.len()) { buf.push(sec.data[j]); j = j + 1; }
        i = i + 1;
    }
    
    
    
}
// Native Korlang Self-Hosted Compiler (New Version)


fun main() -> Int {
    print("Test build Lexer OK\n");
    0
}
